{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff77184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from torch.optim import lr_scheduler\n",
    "from scipy import sparse\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "SEED = 16\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7c7e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyGraphDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each graph lives in its own .npz / .pt / whatever on disk.\n",
    "    __getitem__ loads it just-in-time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, folderpaths):\n",
    "        \"\"\"\n",
    "        meta_csv: a CSV (or list of dicts) with columns:\n",
    "            path_X, path_A_index, path_A_feat, path_L_index, path_L_feat, path_y\n",
    "        Only these tiny strings stay in RAM.\n",
    "        \"\"\"\n",
    "        self.folderpaths = list(folderpaths)\n",
    "\n",
    "    def _import_tensor(self, filename: str, dtype: torch.dtype, is_sparse: bool = False):\n",
    "        \"\"\"\n",
    "        Load a .npz CSR matrix and return either\n",
    "        • a torch.sparse_csr_tensor              (if is_sparse=True)\n",
    "        • a torch.Tensor (dense)                 (otherwise)\n",
    "        \"\"\"\n",
    "        csr = sparse.load_npz(filename).tocsr()\n",
    "\n",
    "        if is_sparse:\n",
    "            crow = torch.from_numpy(csr.indptr.astype(np.int64))\n",
    "            col  = torch.from_numpy(csr.indices.astype(np.int64))\n",
    "            val  = torch.from_numpy(csr.data).to(dtype)\n",
    "            return torch.sparse_csr_tensor(crow, col, val,size=csr.shape, dtype=dtype, requires_grad=False)\n",
    "        # — otherwise densify —\n",
    "        return torch.from_numpy(csr.toarray()).to(dtype)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        folder_path = self.folderpaths[idx]\n",
    "\n",
    "        X = self._import_tensor((folder_path/\"X.npz\"), torch.long, is_sparse=False)\n",
    "        #A = self._import_tensor(folder_path/\"A.npz\", torch.long, True)\n",
    "        Aef = self._import_tensor((folder_path/\"E.npz\"), torch.float32, is_sparse=True)\n",
    "        Aei = np.load((folder_path/\"edge_index.npy\"))\n",
    "        Lef = self._import_tensor((folder_path/\"labels.npz\"), torch.float32, is_sparse=True)\n",
    "        Lei = np.load((folder_path/\"label_index.npy\"))\n",
    "        y = np.load((folder_path/\"label_value.npy\"))\n",
    "\n",
    "        return X, Aei, Aef, Lei, Lef, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folderpaths)\n",
    "\n",
    "def graph_collate(batch):\n",
    "    # batch is a list of tuples\n",
    "    xs, aei, aef, lei, lef, ys = zip(*batch)   # tuples of length B\n",
    "\n",
    "    return (list(xs),                          # list of sparse X\n",
    "            list(aei),                         # list of edge_index\n",
    "            list(aef),                         # list of sparse A_edge_feat\n",
    "            list(lei),\n",
    "            list(lef),\n",
    "            list(ys))                          # dense y can still be list/stack\n",
    "\n",
    "def make_loader(dataset, batch_size=1, shuffle=False):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=graph_collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f02934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = Path(\"../../data/swde_HTMLgraphs/movie/movie\")\n",
    "batchFiles = list(src.rglob(\"[0-9][0-9][0-9][0-9]\"))\n",
    "dataset = LazyGraphDataset(batchFiles)\n",
    "dataloader = make_loader(dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d224978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([621, 96]) [[  0   1]\n",
      " [  1   0]\n",
      " [  1   2]\n",
      " ...\n",
      " [618 585]\n",
      " [619 586]\n",
      " [620 587]] tensor(crow_indices=tensor([    0,     9,    18,  ..., 18552, 18559, 18566]),\n",
      "       col_indices=tensor([ 37,  95, 105,  ..., 192, 195, 196]),\n",
      "       values=tensor([ 1.0000,  1.0000,  1.0000,  ...,  1.0000, 12.0312,\n",
      "                       1.0000]), size=(2758, 197), nnz=18566,\n",
      "       layout=torch.sparse_csr) [[546 509]\n",
      " [509 546]\n",
      " [516 548]\n",
      " [548 516]\n",
      " [516 549]\n",
      " [549 516]\n",
      " [521 470]\n",
      " [470 521]\n",
      " [538 616]\n",
      " [616 538]\n",
      " [522 403]\n",
      " [403 522]\n",
      " [518 588]\n",
      " [588 518]\n",
      " [523 473]\n",
      " [473 523]\n",
      " [528 555]\n",
      " [555 528]\n",
      " [528 556]\n",
      " [556 528]\n",
      " [528 557]\n",
      " [557 528]\n",
      " [528 558]\n",
      " [558 528]\n",
      " [524 589]\n",
      " [589 524]\n",
      " [530 593]\n",
      " [593 530]\n",
      " [530 594]\n",
      " [594 530]\n",
      " [530 595]\n",
      " [595 530]\n",
      " [530 596]\n",
      " [596 530]\n",
      " [530 597]\n",
      " [597 530]\n",
      " [530 598]\n",
      " [598 530]\n",
      " [530 599]\n",
      " [599 530]\n",
      " [530 600]\n",
      " [600 530]\n",
      " [530 601]\n",
      " [601 530]\n",
      " [530 602]\n",
      " [602 530]\n",
      " [530 603]\n",
      " [603 530]\n",
      " [519 398]\n",
      " [398 519]\n",
      " [542 584]\n",
      " [584 542]\n",
      " [536 615]\n",
      " [615 536]\n",
      " [278 325]\n",
      " [325 278]\n",
      " [325 326]\n",
      " [326 325]\n",
      " [301 381]\n",
      " [381 301]\n",
      " [544 618]\n",
      " [618 544]\n",
      " [544 619]\n",
      " [619 544]\n",
      " [544 620]\n",
      " [620 544]\n",
      " [514 387]\n",
      " [387 514]\n",
      " [540 617]\n",
      " [617 540]\n",
      " [257 305]\n",
      " [305 257]\n",
      " [257 307]\n",
      " [307 257]\n",
      " [257 309]\n",
      " [309 257]\n",
      " [257 311]\n",
      " [311 257]\n",
      " [257 313]\n",
      " [313 257]\n",
      " [257 315]\n",
      " [315 257]\n",
      " [257 317]\n",
      " [317 257]\n",
      " [257 319]\n",
      " [319 257]\n",
      " [257 321]\n",
      " [321 257]\n",
      " [257 323]\n",
      " [323 257]\n",
      " [532 604]\n",
      " [604 532]\n",
      " [532 605]\n",
      " [605 532]\n",
      " [532 606]\n",
      " [606 532]\n",
      " [532 607]\n",
      " [607 532]\n",
      " [532 608]\n",
      " [608 532]\n",
      " [534 609]\n",
      " [609 534]\n",
      " [534 610]\n",
      " [610 534]\n",
      " [534 611]\n",
      " [611 534]\n",
      " [534 612]\n",
      " [612 534]\n",
      " [534 613]\n",
      " [613 534]\n",
      " [534 614]\n",
      " [614 534]\n",
      " [526 590]\n",
      " [590 526]\n",
      " [526 591]\n",
      " [591 526]\n",
      " [526 592]\n",
      " [592 526]\n",
      " [513 456]\n",
      " [456 513]\n",
      " [311 304]\n",
      " [304 311]\n",
      " [534 265]\n",
      " [265 534]\n",
      " [257 381]\n",
      " [381 257]\n",
      " [612 610]\n",
      " [610 612]\n",
      " [257 322]\n",
      " [322 257]\n",
      " [595 596]\n",
      " [596 595]\n",
      " [257 304]\n",
      " [304 257]\n",
      " [319 275]\n",
      " [275 319]\n",
      " [605 606]\n",
      " [606 605]\n",
      " [257 316]\n",
      " [316 257]\n",
      " [305 319]\n",
      " [319 305]\n",
      " [614 612]\n",
      " [612 614]\n",
      " [257 312]\n",
      " [312 257]\n",
      " [608 606]\n",
      " [606 608]\n",
      " [599 593]\n",
      " [593 599]\n",
      " [325 275]\n",
      " [275 325]\n",
      " [315 273]\n",
      " [273 315]\n",
      " [311 302]\n",
      " [302 311]\n",
      " [313 316]\n",
      " [316 313]\n",
      " [326 265]\n",
      " [265 326]\n",
      " [309 259]\n",
      " [259 309]\n",
      " [313 323]\n",
      " [323 313]\n",
      " [588 398]\n",
      " [398 588]\n",
      " [301 315]\n",
      " [315 301]\n",
      " [608 605]\n",
      " [605 608]\n",
      " [257 277]\n",
      " [277 257]\n",
      " [473 548]\n",
      " [548 473]\n",
      " [257 327]\n",
      " [327 257]\n",
      " [307 261]\n",
      " [261 307]\n",
      " [257 263]\n",
      " [263 257]\n",
      " [612 611]\n",
      " [611 612]\n",
      " [321 310]\n",
      " [310 321]\n",
      " [381 381]\n",
      " [381 381]\n",
      " [257 271]\n",
      " [271 257]\n",
      " [609 611]\n",
      " [611 609]\n",
      " [607 608]\n",
      " [608 607]\n",
      " [319 261]\n",
      " [261 319]\n",
      " [257 275]\n",
      " [275 257]\n",
      " [309 280]\n",
      " [280 309]\n",
      " [257 273]\n",
      " [273 257]\n",
      " [309 313]\n",
      " [313 309]\n",
      " [325 263]\n",
      " [263 325]\n",
      " [305 261]\n",
      " [261 305]\n",
      " [313 319]\n",
      " [319 313]\n",
      " [257 320]\n",
      " [320 257]\n",
      " [257 280]\n",
      " [280 257]\n",
      " [594 602]\n",
      " [602 594]\n",
      " [323 269]\n",
      " [269 323]\n",
      " [257 325]\n",
      " [325 257]\n",
      " [307 265]\n",
      " [265 307]\n",
      " [278 263]\n",
      " [263 278]\n",
      " [317 602]\n",
      " [602 317]\n",
      " [257 259]\n",
      " [259 257]\n",
      " [257 308]\n",
      " [308 257]\n",
      " [315 319]\n",
      " [319 315]\n",
      " [257 261]\n",
      " [261 257]\n",
      " [325 271]\n",
      " [271 325]\n",
      " [325 267]\n",
      " [267 325]\n",
      " [257 256]\n",
      " [256 257]\n",
      " [594 597]\n",
      " [597 594]\n",
      " [319 324]\n",
      " [324 319]\n",
      " [307 259]\n",
      " [259 307]\n",
      " [598 593]\n",
      " [593 598]\n",
      " [600 599]\n",
      " [599 600]\n",
      " [590 591]\n",
      " [591 590]\n",
      " [602 593]\n",
      " [593 602]\n",
      " [309 324]\n",
      " [324 309]\n",
      " [326 302]\n",
      " [302 326]\n",
      " [301 511]\n",
      " [511 301]\n",
      " [325 273]\n",
      " [273 325]\n",
      " [614 613]\n",
      " [613 614]\n",
      " [315 277]\n",
      " [277 315]\n",
      " [381 273]\n",
      " [273 381]\n",
      " [307 280]\n",
      " [280 307]\n",
      " [591 591]\n",
      " [591 591]\n",
      " [323 265]\n",
      " [265 323]\n",
      " [538 381]\n",
      " [381 538]\n",
      " [456 387]\n",
      " [387 456]\n",
      " [319 307]\n",
      " [307 319]\n",
      " [257 278]\n",
      " [278 257]\n",
      " [301 277]\n",
      " [277 301]\n",
      " [317 323]\n",
      " [323 317]\n",
      " [319 278]\n",
      " [278 319]\n",
      " [257 265]\n",
      " [265 257]\n",
      " [257 326]\n",
      " [326 257]\n",
      " [603 603]\n",
      " [603 603]\n",
      " [602 601]\n",
      " [601 602]\n",
      " [257 310]\n",
      " [310 257]\n",
      " [326 319]\n",
      " [319 326]\n",
      " [602 596]\n",
      " [596 602]\n",
      " [596 600]\n",
      " [600 596]\n",
      " [601 596]\n",
      " [596 601]\n",
      " [305 305]\n",
      " [305 305]\n",
      " [609 610]\n",
      " [610 609]\n",
      " [522 522]\n",
      " [522 522]\n",
      " [323 261]\n",
      " [261 323]\n",
      " [604 606]\n",
      " [606 604]\n",
      " [599 602]\n",
      " [602 599]\n",
      " [523 523]\n",
      " [523 523]\n",
      " [534 534]\n",
      " [534 534]\n",
      " [604 608]\n",
      " [608 604]\n",
      " [592 320]\n",
      " [320 592]\n",
      " [325 320]\n",
      " [320 325]\n",
      " [610 613]\n",
      " [613 610]\n",
      " [257 314]\n",
      " [314 257]\n",
      " [313 278]\n",
      " [278 313]\n",
      " [325 316]\n",
      " [316 325]\n",
      " [600 594]\n",
      " [594 600]\n",
      " [307 315]\n",
      " [315 307]\n",
      " [544 544]\n",
      " [544 544]\n",
      " [593 594]\n",
      " [594 593]\n",
      " [325 319]\n",
      " [319 325]\n",
      " [611 614]\n",
      " [614 611]\n",
      " [323 275]\n",
      " [275 323]\n",
      " [557 557]\n",
      " [557 557]\n",
      " [321 277]\n",
      " [277 321]\n",
      " [555 556]\n",
      " [556 555]\n",
      " [301 275]\n",
      " [275 301]\n",
      " [596 598]\n",
      " [598 596]\n",
      " [325 312]\n",
      " [312 325]] tensor(crow_indices=tensor([   0,    7,   14,   23,   32,   41,   50,   57,\n",
      "                              64,   72,   80,   88,   96,  104,  112,  119,\n",
      "                             126,  135,  144,  153,  162,  171,  180,  189,\n",
      "                             198,  206,  214,  222,  230,  238,  246,  254,\n",
      "                             262,  270,  278,  286,  294,  302,  310,  318,\n",
      "                             326,  334,  342,  350,  358,  366,  374,  382,\n",
      "                             390,  398,  406,  415,  424,  432,  440,  449,\n",
      "                             458,  466,  474,  482,  490,  499,  508,  516,\n",
      "                             524,  532,  540,  548,  556,  565,  574,  583,\n",
      "                             592,  601,  610,  619,  628,  637,  646,  655,\n",
      "                             664,  673,  682,  691,  700,  709,  718,  727,\n",
      "                             736,  745,  754,  762,  770,  779,  788,  796,\n",
      "                             804,  812,  820,  828,  836,  844,  852,  860,\n",
      "                             868,  876,  884,  892,  900,  908,  916,  924,\n",
      "                             932,  941,  950,  958,  966,  974,  982,  989,\n",
      "                             996, 1004, 1012, 1021, 1030, 1037, 1044, 1051,\n",
      "                            1058, 1067, 1076, 1083, 1090, 1099, 1108, 1116,\n",
      "                            1124, 1132, 1140, 1149, 1158, 1165, 1172, 1179,\n",
      "                            1186, 1195, 1204, 1211, 1218, 1225, 1232, 1241,\n",
      "                            1250, 1258, 1266, 1275, 1284, 1292, 1300, 1309,\n",
      "                            1318, 1326, 1334, 1341, 1348, 1356, 1364, 1373,\n",
      "                            1382, 1390, 1398, 1407, 1416, 1425, 1434, 1443,\n",
      "                            1452, 1459, 1466, 1475, 1484, 1491, 1498, 1506,\n",
      "                            1514, 1518, 1522, 1531, 1540, 1547, 1554, 1561,\n",
      "                            1568, 1576, 1584, 1593, 1602, 1611, 1620, 1629,\n",
      "                            1638, 1645, 1652, 1661, 1670, 1678, 1686, 1693,\n",
      "                            1700, 1709, 1718, 1727, 1736, 1743, 1750, 1758,\n",
      "                            1766, 1775, 1784, 1792, 1800, 1809, 1818, 1826,\n",
      "                            1834, 1843, 1852, 1861, 1870, 1877, 1884, 1893,\n",
      "                            1902, 1911, 1920, 1929, 1938, 1944, 1950, 1957,\n",
      "                            1964, 1972, 1980, 1988, 1996, 2003, 2010, 2017,\n",
      "                            2024, 2032, 2040, 2047, 2054, 2062, 2070, 2079,\n",
      "                            2088, 2097, 2106, 2115, 2124, 2131, 2138, 2146,\n",
      "                            2154, 2163, 2172, 2181, 2190, 2194, 2198, 2206,\n",
      "                            2214, 2223, 2232, 2240, 2248, 2255, 2262, 2268,\n",
      "                            2274, 2282, 2290, 2297, 2304, 2313, 2322, 2331,\n",
      "                            2340, 2349, 2358, 2362, 2366, 2373, 2380, 2389,\n",
      "                            2398, 2406, 2414, 2421, 2428, 2435, 2442, 2449,\n",
      "                            2456, 2460, 2464, 2471, 2478, 2482, 2486, 2494,\n",
      "                            2502, 2509, 2516, 2523, 2530, 2534, 2538, 2542,\n",
      "                            2546, 2553, 2560, 2568, 2576, 2584, 2592, 2599,\n",
      "                            2606, 2615, 2624, 2633, 2642, 2650, 2658, 2665,\n",
      "                            2672, 2679, 2686, 2690, 2694, 2701, 2708, 2716,\n",
      "                            2724, 2731, 2738, 2746, 2754, 2758, 2762, 2770,\n",
      "                            2778, 2784, 2790, 2798, 2806, 2813, 2820, 2828,\n",
      "                            2836]),\n",
      "       col_indices=tensor([ 69,  95, 154,  ..., 193, 194, 195]),\n",
      "       values=tensor([   1.0000,    1.0000,    1.0000,  ..., -161.0156,\n",
      "                       167.0000,   33.9219]), size=(360, 197), nnz=2836,\n",
      "       layout=torch.sparse_csr) [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for Xs, Aeis, Aefs, Leis, Lefs, ys in dataloader:\n",
    "    print(Xs[0].shape, Aeis[0].shape, Aefs[0].shape, Leis[0].shape, Lefs[0].shape, ys[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e379c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to normalise the A matrix\n",
    "def symmetric_normalize(A_tilde):\n",
    "    \"\"\"\n",
    "    Performs symmetric normalization of A_tilde (Adj. matrix with self loops):\n",
    "      A_norm = D^{-1/2} * A_tilde * D^{-1/2}\n",
    "    Where D_{ii} = sum of row i in A_tilde.\n",
    "\n",
    "    A_tilde (N, N): Adj. matrix with self loops\n",
    "    Returns:\n",
    "      A_norm : (N, N)\n",
    "    \"\"\"\n",
    "\n",
    "    eps = 1e-5\n",
    "    d = A_tilde.sum(dim=1) + eps\n",
    "    D_inv = torch.diag(torch.pow(d, -0.5))\n",
    "    return (D_inv @ A_tilde @ D_inv).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To advance the model, use the methods in https://arxiv.org/pdf/2311.02921\n",
    "\n",
    "class GraphAttentionNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    HTML‑graph model\n",
    "\n",
    "        X  ─╮\n",
    "            │  GAT( 96 → 64 )\n",
    "            │  ReLU\n",
    "            │  GAT( 64 → 32 )\n",
    "            │  ReLU\n",
    "            └─ Edge‑feature constructor\n",
    "                      [h_i ‖ h_j ‖ φ(e_ij)] ─► MLP(69 → 1)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_dim          : node‑feature size   (= 96)\n",
    "    edge_in_dim     : raw edge‑feature size (= 197)\n",
    "    edge_emb_dim    : Edge-feature MLP output dims\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_dim: int        = 96,\n",
    "                 edge_in_dim: int   = 197,\n",
    "                 edge_emb_dim: int  = 8,\n",
    "                 hidden1: int       = 64,\n",
    "                 hidden2: int       = 32,\n",
    "                 heads:  int        = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        # ── Node-level encoder (edge-aware) ────────────────────────────\n",
    "        self.gat1 = GATv2Conv(in_dim,\n",
    "                              hidden1,\n",
    "                              heads=heads,\n",
    "                              concat=True,\n",
    "                              edge_dim=edge_emb_dim,\n",
    "                              fill_value=\"zeros\")\n",
    "\n",
    "        self.gat2 = GATv2Conv(hidden1 * heads,\n",
    "                              hidden2,\n",
    "                              heads=1,\n",
    "                              concat=True,\n",
    "                              edge_dim=edge_emb_dim,\n",
    "                              fill_value=\"zeros\")\n",
    "\n",
    "        # ── Edge feature projector ────────────── (It is not a linear layer as it does works on a sparse matrix)\n",
    "        self.W_edge = nn.Parameter(torch.empty(edge_in_dim, edge_emb_dim))\n",
    "        nn.init.xavier_uniform_(self.W_edge)\n",
    "\n",
    "        # ── Edge-level MLP decoder (unchanged) ────────────────────────\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden2 * 2 + edge_emb_dim, hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden2, 1)\n",
    "        )\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_dense: torch.Tensor,        # (N_nodes, 96)          sparse\n",
    "        A_edge_index: torch.Tensor,   # (2, nnz_A)             COO  (from A)\n",
    "        A_edge_attr: torch.Tensor,    # (nnz_A, 197)           dense / sparse.mm\n",
    "        E_edge_index: torch.Tensor,   # (2, N_E)               candidates\n",
    "        E_edge_attr: torch.Tensor     # (N_E, 197)             sparse features\n",
    "    ):\n",
    "        # 1) node features\n",
    "        #x = x_sparse.to_dense()\n",
    "        A_edge_emb = torch.sparse.mm(A_edge_attr, self.W_edge)     # (nnz_A , 8)\n",
    "\n",
    "        # 2) edge-aware GATv2 layers\n",
    "        h = F.relu(self.gat1(x_dense, A_edge_index, A_edge_emb))\n",
    "        h = F.relu(self.gat2(h, A_edge_index, A_edge_emb))   # (N_nodes , 32)\n",
    "\n",
    "        # 3) candidate-edge projection  φ(E) = E @ W_edge\n",
    "        E_edge_emb = torch.sparse.mm(E_edge_attr, self.W_edge)     # (N_E , 8)\n",
    "\n",
    "        # 4) gather node embeddings and classify\n",
    "        src, dst = E_edge_index\n",
    "        z = torch.cat([h[src], h[dst], E_edge_emb], dim=1)      # (N_E , 72)\n",
    "        return self.edge_mlp(z).squeeze(-1)                   # (N_E ,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96e35002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits as BCEwLogits\n",
    "\n",
    "IGNORE_LABEL = -1      # change if you use another sentinel for “no label”\n",
    "\n",
    "# ---------- 1. One training epoch -------------------------------------------\n",
    "def train_epoch(\n",
    "    model,\n",
    "    dataloader,               # iterable that yields (X, A, E, edge_index, y)\n",
    "    optimizer,\n",
    "    criterion=BCEwLogits,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    model.train()\n",
    "    total_loss, total_edges = 0.0, 0\n",
    "\n",
    "    for X, A, E, edge_index, y in dataloader:\n",
    "        # Move to device ------------------------------------------------------\n",
    "        X          = X.to(device)\n",
    "        A          = A.to(device)\n",
    "        E          = E.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        y          = y.to(device)\n",
    "\n",
    "        mask = (y != IGNORE_LABEL)          # only supervise labelled edges\n",
    "        if mask.sum() == 0:                 # nothing to learn in this sample\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(X, A, E, edge_index) # (N_edges,)\n",
    "\n",
    "        loss = criterion(logits[mask], y[mask].float())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss   += loss.item() * mask.sum().item()\n",
    "        total_edges  += mask.sum().item()\n",
    "\n",
    "    return total_loss / max(total_edges, 1)   # average over labelled edges\n",
    "\n",
    "\n",
    "# ---------- 2. Full training loop -------------------------------------------\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,                 # edge‑level dataloader\n",
    "    val_loader,                   # edge‑level dataloader\n",
    "    num_epochs       = 100,\n",
    "    lr               = 1e-3,\n",
    "    validate_every   = 10,\n",
    "    patience         = 10,\n",
    "    device           = \"cpu\"\n",
    "):\n",
    "    \"\"\"Train `model` to predict whether an edge exists.\"\"\"\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer  = optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler  = lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"max\", patience=patience, factor=0.5, verbose=False\n",
    "    )\n",
    "\n",
    "    best_val_f1, best_state = 0.0, None\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        loss = train_epoch(model, train_loader, optimizer, device=device)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        # ---- validation -----------------------------------------------------\n",
    "        if epoch % validate_every == 0 or epoch == num_epochs:\n",
    "            val_prec, val_rec, val_f1 = evaluate_edge_model(\n",
    "                model, val_loader, device=device\n",
    "            )\n",
    "            scheduler.step(val_f1)\n",
    "\n",
    "            current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            print(\n",
    "                f\"Epoch {epoch:03d}/{num_epochs}  \"\n",
    "                f\"loss={loss:.4f}  \"\n",
    "                f\"P={val_prec:.3f}  R={val_rec:.3f}  F1={val_f1:.3f}  \"\n",
    "                f\"lr={current_lr:.2e}\"\n",
    "            )\n",
    "\n",
    "            # keep the best‑F1 checkpoint\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                best_state  = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            # early stop if LR too small\n",
    "            if current_lr < 1e-5:\n",
    "                print(\"LR below 1e‑5 → stopping.\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return loss_history, best_state\n",
    "\n",
    "\n",
    "# ---------- 3. Helper: evaluation (precision / recall / F1) -----------------\n",
    "@torch.no_grad()\n",
    "def evaluate_edge_model(model, dataloader, device=\"cpu\", thr=0.5):\n",
    "    model.eval()\n",
    "    tp = fp = fn = 0\n",
    "\n",
    "    for X, A, E, edge_index, y in dataloader:\n",
    "        X, A, E = X.to(device), A.to(device), E.to(device)\n",
    "        edge_index, y = edge_index.to(device), y.to(device)\n",
    "\n",
    "        mask = (y != IGNORE_LABEL)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        logits = model(X, A, E, edge_index)\n",
    "        probs  = torch.sigmoid(logits)\n",
    "\n",
    "        pred = (probs >= thr).long()\n",
    "        tp  += ((pred == 1) & (y == 1) & mask).sum().item()\n",
    "        fp  += ((pred == 1) & (y == 0) & mask).sum().item()\n",
    "        fn  += ((pred == 0) & (y == 1) & mask).sum().item()\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-9)\n",
    "    recall    = tp / (tp + fn + 1e-9)\n",
    "    f1        = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67146255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
