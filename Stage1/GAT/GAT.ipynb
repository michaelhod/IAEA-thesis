{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cff77184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from torch.optim import lr_scheduler\n",
    "from scipy import sparse\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "import io, tarfile, os\n",
    "\n",
    "datafile = \"/vol/bitbucket/mjh24/IAEA-thesis/data/swde_HTMLgraphs.tar\"\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "SEED = 16\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562900ca",
   "metadata": {},
   "source": [
    "***BELOW***\n",
    "If data-loading < 5-10 % of total epoch time with num_workers=0, stick with the simple path.\n",
    "Otherwise, parallel loading with share-friendly torch_sparse.SparseTensor\n",
    "almost always pays off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83fd8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────── Tar-reader dataset\n",
    "class TarGraphDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each graph is stored under its own sub-directory *inside* one .tar:\n",
    "\n",
    "        graphs.tar\n",
    "        ├── 0001/X.npz\n",
    "        ├── 0001/E.npz\n",
    "        ├── 0001/edge_index.npy\n",
    "        ├── 0001/labels.npz\n",
    "        ├── 0001/label_index.npy\n",
    "        ├── 0001/label_value.npy\n",
    "        ├── 0002/…\n",
    "        └── …\n",
    "\n",
    "    The tar is opened once; __getitem__ streams the six files for graph *idx*\n",
    "    straight into memory, converts them to native PyTorch tensors and returns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tar_path: str | Path):\n",
    "        self.tar = tarfile.open(tar_path, mode=\"r:*\")      # gzip/none/…\n",
    "        self.index: dict[str, dict[str, tarfile.TarInfo]] = {}\n",
    "        self.sublen = {}\n",
    "\n",
    "        # Build a small lookup table in RAM  {gid: {filename: tarinfo}}\n",
    "        for member in self.tar.getmembers():\n",
    "            if not member.isfile():\n",
    "                continue\n",
    "\n",
    "            p     = Path(member.name)\n",
    "            gid   = str(p.parent)   # '0007'\n",
    "            fname = p.name          # 'X.npz'\n",
    "\n",
    "            # keep only folders that really are 4-digit graph IDs\n",
    "            if gid[-4:].isdigit():\n",
    "                self.index.setdefault(gid, {})[fname] = member\n",
    "\n",
    "        self.gids = sorted(self.index)\n",
    "\n",
    "        # Remove thos with no labels\n",
    "        for gid, files in self.index.items():\n",
    "            if not files.get(\"labels.npz\"):\n",
    "                self.gids.remove(gid)\n",
    "\n",
    "        # Count\n",
    "        name, counts = np.unique([Path(gid).parent.name for gid in self.gids], return_counts=True)\n",
    "\n",
    "        # Get cumsum\n",
    "        running = 0\n",
    "        for lbl, cnt in zip(name, counts):\n",
    "            self.sublen[lbl] = (running, running + cnt)\n",
    "            running += cnt\n",
    "\n",
    "    # ------------- helpers --------------------------------------------------\n",
    "    @staticmethod\n",
    "    def _npz_to_csr(buf: bytes, dtype=torch.float32):\n",
    "        csr = sparse.load_npz(io.BytesIO(buf)).tocsr()\n",
    "        crow = torch.from_numpy(csr.indptr.astype(np.int64))\n",
    "        col  = torch.from_numpy(csr.indices.astype(np.int64))\n",
    "        val  = torch.from_numpy(csr.data).to(dtype)\n",
    "        return torch.sparse_csr_tensor(\n",
    "            crow, col, val, size=csr.shape, dtype=dtype, requires_grad=False\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _npy_to_tensor(buf: bytes, dtype):\n",
    "        arr = np.load(io.BytesIO(buf), allow_pickle=False)\n",
    "        return torch.from_numpy(arr).to(dtype)\n",
    "\n",
    "    def get_sublen(self, name):\n",
    "        return self.sublen[name]\n",
    "\n",
    "    # ------------- Dataset API ---------------------------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.gids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gid   = self.gids[idx]\n",
    "        files = self.index[gid]\n",
    "\n",
    "        get = lambda name: self.tar.extractfile(files[name]).read()\n",
    "        \n",
    "        fileinfo = gid\n",
    "\n",
    "        X   = self._npz_to_csr(get(\"X.npz\"),       dtype=torch.float32)\n",
    "        Aef = self._npz_to_csr(get(\"E.npz\"),       dtype=torch.float32)\n",
    "        Lef = self._npz_to_csr(get(\"labels.npz\"),  dtype=torch.float32)\n",
    "\n",
    "        Aei = self._npy_to_tensor(get(\"edge_index.npy\"),  dtype=torch.int64)\n",
    "        Lei = self._npy_to_tensor(get(\"label_index.npy\"), dtype=torch.int64)\n",
    "        y   = self._npy_to_tensor(get(\"label_value.npy\"), dtype=torch.int64)\n",
    "\n",
    "        return fileinfo, X, Aei.t().contiguous(), Aef, Lei.t().contiguous(), Lef, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "316ad981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_csr(blocks):\n",
    "    \"\"\"\n",
    "    Vertically stack CSR matrices that all share the same n_cols.\n",
    "    Keeps sparsity and returns a single torch.sparse_csr_tensor.\n",
    "    \"\"\"\n",
    "    crow_bufs, col_bufs, val_bufs = [], [], []\n",
    "    nnz_so_far, n_rows, n_cols = 0, 0, blocks[0].size(1)\n",
    "\n",
    "    for k, csr in enumerate(blocks):\n",
    "        crow = csr.crow_indices().clone()          # (n_rows_k + 1,)\n",
    "\n",
    "        # 1) shift by *cumulative* nnz so far\n",
    "        crow += nnz_so_far\n",
    "\n",
    "        # 2) drop the leading 0 for every block after the first\n",
    "        if k > 0:\n",
    "            crow = crow[1:]\n",
    "\n",
    "        crow_bufs.append(crow)\n",
    "        col_bufs.append(csr.col_indices())\n",
    "        val_bufs.append(csr.values())\n",
    "\n",
    "        nnz_so_far += csr.values().numel()\n",
    "        n_rows     += csr.size(0)\n",
    "\n",
    "    crow_cat = torch.cat(crow_bufs)\n",
    "    col_cat  = torch.cat(col_bufs)\n",
    "    val_cat  = torch.cat(val_bufs)\n",
    "\n",
    "    return torch.sparse_csr_tensor(\n",
    "        crow_cat, col_cat, val_cat,\n",
    "        size=(n_rows, n_cols),\n",
    "        dtype=val_cat.dtype,\n",
    "        device=val_cat.device,\n",
    "        requires_grad=False\n",
    "    )\n",
    "\n",
    "\n",
    "def sparse_graph_collate(batch):\n",
    "    # unpack each graph\n",
    "    filenames, xs, aei, aef, lei, lef, ys = zip(*batch)\n",
    "\n",
    "    # node-count prefix sum for shifting\n",
    "    node_offsets = torch.cumsum(\n",
    "        torch.tensor([0] + [x.size(0) for x in xs[:-1]]), 0)\n",
    "\n",
    "    # ----- merge node features (CSR) -----------------------------\n",
    "    X_batch = concat_csr(xs)\n",
    "\n",
    "    # ----- merge structural edges --------------------------------\n",
    "    Aei_shifted = []\n",
    "    for off, ei in zip(node_offsets, aei):\n",
    "        Aei_shifted.append(ei + off)   # shift both rows\n",
    "    Aei_batch = torch.cat(Aei_shifted, dim=1)   # (2 , E_tot)\n",
    "\n",
    "    Aef_batch = concat_csr(aef)\n",
    "\n",
    "    # ----- merge label edges -------------------------------------\n",
    "    Lei_shifted = []\n",
    "    for off, ei in zip(node_offsets, lei):\n",
    "        Lei_shifted.append(ei + off)\n",
    "    Lei_batch = torch.cat(Lei_shifted, dim=1)\n",
    "\n",
    "    Lef_batch = concat_csr(lef)\n",
    "    y_batch   = torch.cat(ys)\n",
    "\n",
    "    return filenames, X_batch, Aei_batch, Aef_batch, Lei_batch, Lef_batch, y_batch\n",
    "\n",
    "def debug_collate(batch):\n",
    "    _, xs, aei, aef, lei, lef, ys = zip(*batch)\n",
    "    print(\"--- one mini-batch ---\")\n",
    "    for i, X in enumerate(xs):\n",
    "        print(f\"graph {i}:  nodes={X.size(0):4d}   \"\n",
    "              f\"struct-edges={aei[i].shape[1]:4d}   \"\n",
    "              f\"label-edges={lei[i].shape[1]:3d}\")\n",
    "    # then call the real collate to keep training code unchanged\n",
    "    return sparse_graph_collate(batch)\n",
    "\n",
    "# ───────────────────────────────────────────────────────── loader utilities\n",
    "def identity_collate(batch):\n",
    "    \"\"\"batch == list of length 1 → return that single sample untouched.\"\"\"\n",
    "    return batch[0]\n",
    "\n",
    "def make_loader(ds, batch_size=1, shuffle=False):\n",
    "    return DataLoader(ds,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      collate_fn=sparse_graph_collate,\n",
    "                      num_workers=0,\n",
    "                      pin_memory=True)    # fast GPU transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec604253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset   = TarGraphDataset(\"../../data/swde_HTMLgraphs.tar\")\n",
    "# loader    = make_loader(dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# next(iter(loader))\n",
    "\n",
    "# count = 0\n",
    "# for fileinfo, X, Aei, Aef, Lei, Lef, y in loader:\n",
    "#     print(fileinfo)\n",
    "#     count +=1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7c7e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a lazy loader for individual files\n",
    "\n",
    "# class LazyGraphDataset(Dataset):\n",
    "#     \"\"\"\n",
    "#     Each graph lives in its own .npz / .pt / whatever on disk.\n",
    "#     __getitem__ loads it just-in-time.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, folderpaths):\n",
    "#         \"\"\"\n",
    "#         meta_csv: a CSV (or list of dicts) with columns:\n",
    "#             path_X, path_A_index, path_A_feat, path_L_index, path_L_feat, path_y\n",
    "#         Only these tiny strings stay in RAM.\n",
    "#         \"\"\"\n",
    "#         self.folderpaths = list(folderpaths)\n",
    "\n",
    "#     def _import_tensor(self, filename: str, dtype: torch.dtype, is_sparse: bool = False):\n",
    "#         \"\"\"\n",
    "#         Load a .npz CSR matrix and return either\n",
    "#         • a torch.sparse_csr_tensor              (if is_sparse=True)\n",
    "#         • a torch.Tensor (dense)                 (otherwise)\n",
    "#         \"\"\"\n",
    "#         csr = sparse.load_npz(filename).tocsr()\n",
    "\n",
    "#         if is_sparse:\n",
    "#             crow = torch.from_numpy(csr.indptr.astype(np.int64))\n",
    "#             col  = torch.from_numpy(csr.indices.astype(np.int64))\n",
    "#             val  = torch.from_numpy(csr.data).to(dtype)\n",
    "#             return torch.sparse_csr_tensor(crow, col, val,size=csr.shape, dtype=dtype, requires_grad=False)\n",
    "#         # — otherwise densify —\n",
    "#         return torch.from_numpy(csr.toarray()).to(dtype)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         folder_path = self.folderpaths[idx]\n",
    "\n",
    "#         X = self._import_tensor((folder_path/\"X.npz\"), torch.float32, is_sparse=False)\n",
    "#         #A = self._import_tensor(folder_path/\"A.npz\", torch.long, True)\n",
    "#         Aef = self._import_tensor((folder_path/\"E.npz\"), torch.float32, is_sparse=True)\n",
    "#         Aei = torch.from_numpy(np.load((folder_path/\"edge_index.npy\")))\n",
    "#         Lef = self._import_tensor((folder_path/\"labels.npz\"), torch.float32, is_sparse=True)\n",
    "#         Lei = torch.from_numpy(np.load((folder_path/\"label_index.npy\")))\n",
    "#         y = torch.from_numpy(np.load((folder_path/\"label_value.npy\")))\n",
    "\n",
    "#         return X, Aei, Aef, Lei, Lef, y\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.folderpaths)\n",
    "\n",
    "# def graph_collate(batch):\n",
    "#     # batch is a list of tuples\n",
    "#     xs, aei, aef, lei, lef, ys = zip(*batch)   # tuples of length B\n",
    "\n",
    "#     return (list(xs),                          # list of sparse X\n",
    "#             list(aei),                         # list of edge_index\n",
    "#             list(aef),                         # list of sparse A_edge_feat\n",
    "#             list(lei),\n",
    "#             list(lef),\n",
    "#             list(ys))                          # dense y can still be list/stack\n",
    "\n",
    "# def make_loader(dataset, batch_size=1, shuffle=False):\n",
    "#     return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=graph_collate, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f02934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def walk_limited(root: Path, max_depth: int, pat: str):\n",
    "#     root_depth = len(root.parts)\n",
    "#     for dirpath, dirnames, _ in os.walk(root):\n",
    "#         depth = len(Path(dirpath).parts) - root_depth\n",
    "#         if depth > max_depth:\n",
    "#             # prune traversal\n",
    "#             dirnames[:] = []\n",
    "#             continue\n",
    "#         for d in dirnames:\n",
    "#             p = Path(dirpath, d)\n",
    "#             if p.match(pat):\n",
    "#                 yield p\n",
    "\n",
    "# src = Path(\"/vol/bitbucket/mjh24/IAEA-thesis/data/swde_HTMLgraphs/movie/movie\")\n",
    "# batch_dirs = list(walk_limited(src, max_depth=2, pat='[0-9][0-9][0-9][0-9]'))\n",
    "# print(src.exists())\n",
    "# batchFiles = list(src.rglob(\"[0-9][0-9][0-9][0-9]\"))\n",
    "# print(len(batchFiles))\n",
    "# dataset = LazyGraphDataset(batchFiles)\n",
    "# dataloader = make_loader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d224978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Xs, Aeis, Aefs, Leis, Lefs, ys in dataloader:\n",
    "#     print(Xs[0].shape, Aeis[0].shape, Aefs[0].shape, Leis[0].shape, Lefs[0].shape, ys[0].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e379c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper function to normalise the A matrix\n",
    "# def symmetric_normalize(A_tilde):\n",
    "#     \"\"\"\n",
    "#     Performs symmetric normalization of A_tilde (Adj. matrix with self loops):\n",
    "#       A_norm = D^{-1/2} * A_tilde * D^{-1/2}\n",
    "#     Where D_{ii} = sum of row i in A_tilde.\n",
    "\n",
    "#     A_tilde (N, N): Adj. matrix with self loops\n",
    "#     Returns:\n",
    "#       A_norm : (N, N)\n",
    "#     \"\"\"\n",
    "\n",
    "#     eps = 1e-5\n",
    "#     d = A_tilde.sum(dim=1) + eps\n",
    "#     D_inv = torch.diag(torch.pow(d, -0.5))\n",
    "#     return (D_inv @ A_tilde @ D_inv).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0048a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_live(\n",
    "    train_vals,\n",
    "    val_vals,\n",
    "    save_path,\n",
    "    xlabel=\"Epoch\",\n",
    "    ylabel=\"Metric\",\n",
    "    title=\"Training & Validation\",\n",
    "    fig_ax=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Live‐updating single‐axis plot of training vs validation values.\n",
    "    Call each epoch with the growing lists `train_vals` and `val_vals`.\n",
    "    Returns (fig, ax) so you can pass them back in.\n",
    "    \"\"\"\n",
    "    # First call: create figure & axis\n",
    "    if fig_ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8,5))\n",
    "    else:\n",
    "        fig, ax = fig_ax\n",
    "\n",
    "    # Clear and redraw\n",
    "    ax.cla()\n",
    "    epochs = range(1, len(train_vals) + 1)\n",
    "\n",
    "    ax.plot(epochs, train_vals, '-o', label=\"Train\", markersize=4)\n",
    "    ax.plot(epochs, val_vals,   '-s', label=\"Val\",   markersize=4)\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(Path(save_path), dpi=150)\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "749c7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To advance the model, use the methods in https://arxiv.org/pdf/2311.02921\n",
    "\n",
    "class GraphAttentionNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    HTML‑graph model\n",
    "\n",
    "        X  ─╮\n",
    "            │  GAT( 96 → 64 )\n",
    "            │  ReLU\n",
    "            │  GAT( 64 → 32 )\n",
    "            │  ReLU\n",
    "            └─ Edge‑feature constructor\n",
    "                      [h_i ‖ h_j ‖ φ(e_ij)] ─► MLP(69 → 1)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_dim          : node‑feature size   (= 96)\n",
    "    edge_in_dim     : raw edge‑feature size (= 197)\n",
    "    edge_emb_dim    : Edge-feature MLP output dims\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_dim: int        = 96,\n",
    "                 edge_in_dim: int   = 197,\n",
    "                 edge_emb_dim: int  = 8,\n",
    "                 hidden1: int       = 64,\n",
    "                 hidden2: int       = 32,\n",
    "                 heads:  int        = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        # ── Node-level encoder (edge-aware) ────────────────────────────\n",
    "        self.gat1 = GATv2Conv(in_dim,\n",
    "                              hidden1,\n",
    "                              heads=heads,\n",
    "                              concat=True,\n",
    "                              edge_dim=edge_emb_dim,\n",
    "                              fill_value=0.0)\n",
    "\n",
    "        self.gat2 = GATv2Conv(hidden1 * heads,\n",
    "                              hidden2,\n",
    "                              heads=1,\n",
    "                              concat=True,\n",
    "                              edge_dim=edge_emb_dim,\n",
    "                              fill_value=0.0)\n",
    "\n",
    "        # ── Edge feature projector ────────────── (It is not an explicit linear layer as it works on a sparse matrix)\n",
    "        self.W_edge = nn.Parameter(torch.empty(edge_in_dim, edge_emb_dim))\n",
    "        nn.init.xavier_uniform_(self.W_edge)\n",
    "\n",
    "        # ── Edge-level MLP decoder (unchanged) ────────────────────────\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden2 * 2 + edge_emb_dim, hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden2, 1)\n",
    "        )\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_dense: torch.Tensor,        # (N_nodes, 96)          sparse\n",
    "        A_edge_index: torch.Tensor,   # (2, nnz_A)             COO  (from A)\n",
    "        A_edge_attr: torch.Tensor,    # (nnz_A, 197)           dense / sparse.mm\n",
    "        E_edge_index: torch.Tensor,   # (2, N_E)               candidates\n",
    "        E_edge_attr: torch.Tensor     # (N_E, 197)             sparse features\n",
    "    ):\n",
    "        # 1) node features\n",
    "        #x = x_sparse.to_dense()\n",
    "        A_edge_emb = torch.sparse.mm(A_edge_attr, self.W_edge)     # (nnz_A , 8)\n",
    "        \n",
    "        # 2) edge-aware GATv2 layers\n",
    "        h = F.relu(self.gat1(x_dense, A_edge_index, A_edge_emb))\n",
    "        h = F.relu(self.gat2(h, A_edge_index, A_edge_emb))   # (N_nodes , 32)\n",
    "        \n",
    "        # 3) candidate-edge projection  φ(E) = E @ W_edge\n",
    "        E_edge_emb = torch.sparse.mm(E_edge_attr, self.W_edge)     # (N_E , 8)\n",
    "        \n",
    "        # 4) gather node embeddings and classify\n",
    "        src, dst = E_edge_index\n",
    "        z = torch.cat([h[src], h[dst], E_edge_emb], dim=1)      # (N_E , 72)\n",
    "        return self.edge_mlp(z).squeeze(-1)                   # (N_E ,) returns the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96e35002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits as BCEwLogits\n",
    "\n",
    "CLIP_NORM = 1.0           # gradient clipping\n",
    "\n",
    "\n",
    "# ---------- one epoch --------------------------------------------------------\n",
    "def train_epoch(model, loader, optimizer,\n",
    "                criterion=BCEwLogits, device=\"cpu\"):\n",
    "\n",
    "    model.train()\n",
    "    running_loss, running_edges = 0.0, 0\n",
    "    count = 0\n",
    "    l = len(loader)\n",
    "\n",
    "    for _, X, Aei, Aef, Lei, Lef, y in loader:\n",
    "        count += 1\n",
    "        X, Aei, Aef = X.to(device), Aei.to(device), Aef.to(device)\n",
    "        Lei, Lef, y = Lei.to(device), Lef.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(X, Aei, Aef, Lei, Lef)          # (N_label,)\n",
    "        loss   = criterion(logits, y.float())\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss  += loss.item() * y.numel()\n",
    "        running_edges += y.numel()\n",
    "\n",
    "        if count % 20 == 0:\n",
    "            print(f\"file {count}/{l}\"\n",
    "                    f\"loss={loss:.4f}\")\n",
    "\n",
    "    return running_loss / running_edges\n",
    "\n",
    "\n",
    "# ---------- evaluation -------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def eval_edge_model(model, loader, criterion, device=\"cpu\", thr=0.5):\n",
    "    model.eval()\n",
    "    TP = FP = FN = 0\n",
    "    running_loss, running_edges = 0.0, 0\n",
    "\n",
    "    filenames = []\n",
    "    for f, X, Aei, Aef, Lei, Lef, y in loader:\n",
    "        filenames += f\n",
    "        X, Aei, Aef = X.to(device), Aei.to(device), Aef.to(device)\n",
    "        Lei, Lef, y = Lei.to(device), Lef.to(device), y.to(device)\n",
    "\n",
    "        logits = model(X, Aei, Aef, Lei, Lef)\n",
    "        loss   = criterion(logits, y.float())\n",
    "        running_loss  += loss.item() * y.numel()\n",
    "        running_edges += y.numel()\n",
    "        probs  = torch.sigmoid(logits)\n",
    "\n",
    "        pred = (probs >= thr).long()\n",
    "        TP  += ((pred == 1) & (y == 1)).sum().item()\n",
    "        FP  += ((pred == 1) & (y == 0)).sum().item()\n",
    "        FN  += ((pred == 0) & (y == 1)).sum().item()\n",
    "\n",
    "    print(f\"Validating {np.unique([filename[:-5] for filename in filenames])} website type\")\n",
    "    prec = TP / (TP + FP + 1e-9)\n",
    "    rec  = TP / (TP + FN + 1e-9)\n",
    "    f1   = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "    return running_loss / running_edges, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "67146255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                load_checkpoint,\n",
    "                num_epochs     = 100,\n",
    "                lr             = 1e-3,\n",
    "                validate_every = 10,\n",
    "                patience       = 10,\n",
    "                device         = \"cpu\"):\n",
    "\n",
    "    print(\"Woo lets go\")\n",
    "\n",
    "    model_path = \"./model_in_training.pth\"\n",
    "    if os.path.exists(model_path) and load_checkpoint:\n",
    "        print(\"loading existing model...\")\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    opt   = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    sched = lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\",\n",
    "                                          patience=patience, factor=0.5)\n",
    "    criterion = BCEwLogits\n",
    "\n",
    "    best_f1, fig_ax, best_state, train_loss, val_loss = 0.0, None, None, [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        \n",
    "        loss = train_epoch(model, train_loader, opt, criterion=criterion, device=device)\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        if epoch % validate_every == 0 or epoch == num_epochs:\n",
    "            loss, p, r, f1 = eval_edge_model(model, val_loader, criterion, device=device)\n",
    "            val_loss.append(loss)\n",
    "            sched.step(f1)\n",
    "\n",
    "            lr_now = opt.param_groups[0][\"lr\"]\n",
    "            print(f\"Epoch {epoch:03d}/{num_epochs} \"\n",
    "                  f\"loss={loss:.4f}  P={p:.3f} R={r:.3f} F1={f1:.3f}  lr={lr_now:.2e}\")\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_state = f1, copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if lr_now < 1e-5:\n",
    "                print(\"Stop: LR < 1e-5\")\n",
    "                break\n",
    "\n",
    "            fig_ax = plot_metrics_live(\n",
    "                train_loss,\n",
    "                val_loss,\n",
    "                \"CurrentRun\",\n",
    "                xlabel=\"Epoch\",\n",
    "                ylabel=\"Loss\",\n",
    "                title=\"Model Performance\",\n",
    "                fig_ax=fig_ax\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return best_state, train_loss, val_loss, fig_ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7bbfe9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Woo lets go\n",
      "file 20/100loss=0.6690\n",
      "file 40/100loss=0.5517\n",
      "file 60/100loss=0.5287\n",
      "file 80/100loss=0.5088\n",
      "file 100/100loss=0.5110\n",
      "Validating ['swde_HTMLgraphs/movie/movie/movie-allmovie(2000)'] website type\n",
      "Epoch 001/50 loss=0.5988  P=0.949 R=0.026 F1=0.052  lr=1.00e-03\n",
      "file 20/100loss=0.4730\n",
      "file 40/100loss=0.4859\n",
      "file 60/100loss=0.4705\n",
      "file 80/100loss=0.4510\n",
      "file 100/100loss=0.4668\n",
      "Validating ['swde_HTMLgraphs/movie/movie/movie-allmovie(2000)'] website type\n",
      "Epoch 002/50 loss=0.5931  P=0.543 R=0.098 F1=0.165  lr=1.00e-03\n",
      "file 20/100loss=0.4133\n",
      "file 40/100loss=0.3987\n",
      "file 60/100loss=0.3865\n",
      "file 80/100loss=0.3883\n",
      "file 100/100loss=0.3779\n",
      "Validating ['swde_HTMLgraphs/movie/movie/movie-allmovie(2000)'] website type\n",
      "Epoch 003/50 loss=0.6450  P=0.452 R=0.171 F1=0.248  lr=1.00e-03\n",
      "file 20/100loss=0.3680\n",
      "file 40/100loss=0.3674\n",
      "file 60/100loss=0.3574\n",
      "file 80/100loss=0.3457\n",
      "file 100/100loss=0.3353\n",
      "Validating ['swde_HTMLgraphs/movie/movie/movie-allmovie(2000)'] website type\n",
      "Epoch 004/50 loss=0.8198  P=0.389 R=0.179 F1=0.245  lr=1.00e-03\n",
      "file 20/100loss=0.3289\n",
      "file 40/100loss=0.3279\n",
      "file 60/100loss=0.3279\n",
      "file 80/100loss=0.3144\n",
      "file 100/100loss=0.3251\n",
      "Validating ['swde_HTMLgraphs/movie/movie/movie-allmovie(2000)'] website type\n",
      "Epoch 005/50 loss=0.9676  P=0.452 R=0.197 F1=0.274  lr=1.00e-03\n",
      "file 20/100loss=0.3150\n",
      "file 40/100loss=0.3039\n",
      "file 60/100loss=0.2934\n",
      "file 80/100loss=0.3115\n",
      "file 100/100loss=0.2875\n",
      "Validating ['swde_HTMLgraphs/movie/movie/movie-allmovie(2000)'] website type\n",
      "Epoch 006/50 loss=1.1067  P=0.433 R=0.165 F1=0.239  lr=1.00e-03\n",
      "file 20/100loss=0.2819\n",
      "file 40/100loss=0.2814\n",
      "file 60/100loss=0.2815\n",
      "file 80/100loss=0.2982\n",
      "file 100/100loss=0.2537\n",
      "Validating ['swde_HTMLgraphs/movie/movie/movie-allmovie(2000)'] website type\n",
      "Epoch 007/50 loss=1.1938  P=0.446 R=0.220 F1=0.295  lr=1.00e-03\n",
      "file 20/100loss=0.2618\n",
      "file 40/100loss=0.2678\n",
      "file 60/100loss=0.2553\n",
      "file 80/100loss=0.2464\n",
      "file 100/100loss=0.2486\n",
      "Validating ['swde_HTMLgraphs/movie/movie/movie-allmovie(2000)'] website type\n",
      "Epoch 008/50 loss=1.3033  P=0.413 R=0.206 F1=0.275  lr=1.00e-03\n",
      "file 20/100loss=0.2458\n",
      "file 40/100loss=0.2500\n",
      "file 60/100loss=0.2437\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     15\u001b[39m val_loader = make_loader(val_ds, batch_size=\u001b[32m256\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     17\u001b[39m model = GraphAttentionNetwork(in_dim = \u001b[32m96\u001b[39m, edge_in_dim = \u001b[32m197\u001b[39m, edge_emb_dim = \u001b[32m8\u001b[39m, hidden1 = \u001b[32m64\u001b[39m, hidden2 = \u001b[32m32\u001b[39m, heads = \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m _, trainloss, valloss, fig_ax = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m            \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m            \u001b[49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalidate_every\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m       \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m         \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, load_checkpoint, num_epochs, lr, validate_every, patience, device)\u001b[39m\n\u001b[32m     25\u001b[39m best_f1, fig_ax, best_state, train_loss, val_loss = \u001b[32m0.0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, [], []\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     train_loss.append(loss)\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m epoch % validate_every == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch == num_epochs:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, optimizer, criterion, device)\u001b[39m\n\u001b[32m     16\u001b[39m count = \u001b[32m0\u001b[39m\n\u001b[32m     17\u001b[39m l = \u001b[38;5;28mlen\u001b[39m(loader)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAef\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAei\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAef\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/mjh24/IAEA-thesis/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/mjh24/IAEA-thesis/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/mjh24/IAEA-thesis/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/mjh24/IAEA-thesis/.venv/lib/python3.12/site-packages/torch/utils/data/dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mTarGraphDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     83\u001b[39m fileinfo = gid\n\u001b[32m     85\u001b[39m X   = \u001b[38;5;28mself\u001b[39m._npz_to_csr(get(\u001b[33m\"\u001b[39m\u001b[33mX.npz\u001b[39m\u001b[33m\"\u001b[39m),       dtype=torch.float32)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m Aef = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_npz_to_csr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mE.npz\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m Lef = \u001b[38;5;28mself\u001b[39m._npz_to_csr(get(\u001b[33m\"\u001b[39m\u001b[33mlabels.npz\u001b[39m\u001b[33m\"\u001b[39m),  dtype=torch.float32)\n\u001b[32m     89\u001b[39m Aei = \u001b[38;5;28mself\u001b[39m._npy_to_tensor(get(\u001b[33m\"\u001b[39m\u001b[33medge_index.npy\u001b[39m\u001b[33m\"\u001b[39m),  dtype=torch.int64)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mTarGraphDataset._npz_to_csr\u001b[39m\u001b[34m(buf, dtype)\u001b[39m\n\u001b[32m     59\u001b[39m col  = torch.from_numpy(csr.indices.astype(np.int64))\n\u001b[32m     60\u001b[39m val  = torch.from_numpy(csr.data).to(dtype)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msparse_csr_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcsr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     63\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = TarGraphDataset(datafile)\n",
    "N = len(dataset)\n",
    "# n_train = int(0.95 * N)\n",
    "# n_val   = N - n_train\n",
    "# train_ds, val_ds = random_split(dataset, [n_train, n_val])\n",
    "val_start, val_end = dataset.get_sublen('movie-allmovie(2000)')\n",
    "val_idx = list(range(val_start, val_end))  \n",
    "train_idx = list(set(range(N)) - set(val_idx))\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds   = Subset(dataset, val_idx)\n",
    "\n",
    "load_checkpoint = True\n",
    "\n",
    "train_loader = make_loader(train_ds, batch_size=256, shuffle=True)\n",
    "val_loader = make_loader(val_ds, batch_size=256, shuffle=True)\n",
    "\n",
    "model = GraphAttentionNetwork(in_dim = 96, edge_in_dim = 197, edge_emb_dim = 8, hidden1 = 64, hidden2 = 32, heads = 1)\n",
    "\n",
    "_, trainloss, valloss, fig_ax = train_model(model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            load_checkpoint,\n",
    "            num_epochs     = 50,\n",
    "            lr             = 1e-3,\n",
    "            validate_every = 1,\n",
    "            patience       = 1,\n",
    "            device         = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aabc1814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "torch.save(model.state_dict(), \"modelbatch50epoch.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
