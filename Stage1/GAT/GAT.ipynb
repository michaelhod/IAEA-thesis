{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cff77184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from torch.optim import lr_scheduler\n",
    "from scipy import sparse\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "import io, tarfile, os\n",
    "import copy\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits as BCEwLogits\n",
    "from GATModel import GraphAttentionNetwork\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.current_device()\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "datafile = \"/vol/bitbucket/mjh24/IAEA-thesis/data/swde_HTMLgraphs_newtags.tar\"\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562900ca",
   "metadata": {},
   "source": [
    "***BELOW***\n",
    "If data-loading < 5-10 % of total epoch time with num_workers=0, stick with the simple path.\n",
    "Otherwise, parallel loading with share-friendly torch_sparse.SparseTensor\n",
    "almost always pays off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83fd8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────── Tar-reader dataset\n",
    "class TarGraphDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each graph is stored under its own sub-directory *inside* one .tar:\n",
    "\n",
    "        graphs.tar\n",
    "        ├── 0001/X.npz\n",
    "        ├── 0001/E.npz\n",
    "        ├── 0001/edge_index.npy\n",
    "        ├── 0001/labels.npz\n",
    "        ├── 0001/label_index.npy\n",
    "        ├── 0001/label_value.npy\n",
    "        ├── 0002/…\n",
    "        └── …\n",
    "\n",
    "    The tar is opened once; __getitem__ streams the six files for graph *idx*\n",
    "    straight into memory, converts them to native PyTorch tensors and returns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tar_path: str | Path):\n",
    "        self.tar = tarfile.open(tar_path, mode=\"r:*\")      # gzip/none/…\n",
    "        self.index: dict[str, dict[str, tarfile.TarInfo]] = {}\n",
    "        self.sublen = {}\n",
    "\n",
    "        # Build a small lookup table in RAM  {gid: {filename: tarinfo}}\n",
    "        for member in self.tar.getmembers():\n",
    "            if not member.isfile():\n",
    "                continue\n",
    "\n",
    "            p     = Path(member.name)\n",
    "            gid   = str(p.parent)   # '0007'\n",
    "            fname = p.name          # 'X.npz'\n",
    "\n",
    "            # keep only folders that really are 4-digit graph IDs\n",
    "            if gid[-4:].isdigit():\n",
    "                self.index.setdefault(gid, {})[fname] = member\n",
    "\n",
    "        self.gids = sorted(self.index)\n",
    "\n",
    "        # Remove thos with no labels\n",
    "        for gid, files in self.index.items():\n",
    "            if not files.get(\"labels.npz\"):\n",
    "                self.gids.remove(gid)\n",
    "\n",
    "        # Count\n",
    "        name, counts = np.unique([Path(gid).parent.name for gid in self.gids], return_counts=True)\n",
    "\n",
    "        # Get cumsum\n",
    "        running = 0\n",
    "        for lbl, cnt in zip(name, counts):\n",
    "            self.sublen[lbl] = (running, running + cnt)\n",
    "            running += cnt\n",
    "\n",
    "    # ------------- helpers --------------------------------------------------\n",
    "    @staticmethod\n",
    "    def _npz_to_csr(buf: bytes, dtype=torch.float32):\n",
    "        csr = sparse.load_npz(io.BytesIO(buf)).tocsr()\n",
    "        crow = torch.from_numpy(csr.indptr.astype(np.int64))\n",
    "        col  = torch.from_numpy(csr.indices.astype(np.int64))\n",
    "        val  = torch.from_numpy(csr.data).to(dtype)\n",
    "        return torch.sparse_csr_tensor(\n",
    "            crow, col, val, size=csr.shape, dtype=dtype, requires_grad=False\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _npy_to_tensor(buf: bytes, dtype):\n",
    "        arr = np.load(io.BytesIO(buf), allow_pickle=False)\n",
    "        return torch.from_numpy(arr).to(dtype)\n",
    "\n",
    "    def get_sublen(self, name):\n",
    "        return self.sublen[name]\n",
    "\n",
    "    # ------------- Dataset API ---------------------------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.gids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gid   = self.gids[idx]\n",
    "        files = self.index[gid]\n",
    "\n",
    "        get = lambda name: self.tar.extractfile(files[name]).read()\n",
    "        \n",
    "        fileinfo = gid\n",
    "\n",
    "        X   = self._npz_to_csr(get(\"X.npz\"),       dtype=torch.float32)\n",
    "        Aef = self._npz_to_csr(get(\"E.npz\"),       dtype=torch.float32)\n",
    "        Lef = self._npz_to_csr(get(\"labels.npz\"),  dtype=torch.float32)\n",
    "\n",
    "        Aei = self._npy_to_tensor(get(\"edge_index.npy\"),  dtype=torch.int64)\n",
    "        Lei = self._npy_to_tensor(get(\"label_index.npy\"), dtype=torch.int64)\n",
    "        y   = self._npy_to_tensor(get(\"label_value.npy\"), dtype=torch.int64)\n",
    "        titleIdx = self._npy_to_tensor(get(\"titleIdx.npy\"), dtype=torch.int64)\n",
    "\n",
    "        return fileinfo, X, Aei.t().contiguous(), Aef, Lei.t().contiguous(), Lef, y, titleIdx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "316ad981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_csr(blocks):\n",
    "    \"\"\"\n",
    "    Vertically stack CSR matrices that all share the same n_cols.\n",
    "    Keeps sparsity and returns a single torch.sparse_csr_tensor.\n",
    "    \"\"\"\n",
    "    crow_bufs, col_bufs, val_bufs = [], [], []\n",
    "    nnz_so_far, n_rows, n_cols = 0, 0, blocks[0].size(1)\n",
    "\n",
    "    for k, csr in enumerate(blocks):\n",
    "        crow = csr.crow_indices().clone()          # (n_rows_k + 1,)\n",
    "\n",
    "        # 1) shift by *cumulative* nnz so far\n",
    "        crow += nnz_so_far\n",
    "\n",
    "        # 2) drop the leading 0 for every block after the first\n",
    "        if k > 0:\n",
    "            crow = crow[1:]\n",
    "\n",
    "        crow_bufs.append(crow)\n",
    "        col_bufs.append(csr.col_indices())\n",
    "        val_bufs.append(csr.values())\n",
    "\n",
    "        nnz_so_far += csr.values().numel()\n",
    "        n_rows     += csr.size(0)\n",
    "\n",
    "    crow_cat = torch.cat(crow_bufs)\n",
    "    col_cat  = torch.cat(col_bufs)\n",
    "    val_cat  = torch.cat(val_bufs)\n",
    "\n",
    "    return torch.sparse_csr_tensor(\n",
    "        crow_cat, col_cat, val_cat,\n",
    "        size=(n_rows, n_cols),\n",
    "        dtype=val_cat.dtype,\n",
    "        device=val_cat.device,\n",
    "        requires_grad=False\n",
    "    )\n",
    "\n",
    "\n",
    "def sparse_graph_collate(batch):\n",
    "    # unpack each graph\n",
    "    filenames, xs, aei, aef, lei, lef, ys, titleIdxs = zip(*batch)\n",
    "\n",
    "    # node-count prefix sum for shifting\n",
    "    node_offsets = torch.cumsum(\n",
    "        torch.tensor([0] + [x.size(0) for x in xs[:-1]]), 0)\n",
    "\n",
    "    # ----- merge node features (CSR) -----------------------------\n",
    "    X_batch = concat_csr(xs)\n",
    "\n",
    "    # ----- merge structural edges --------------------------------\n",
    "    Aei_shifted = []\n",
    "    for off, ei in zip(node_offsets, aei):\n",
    "        Aei_shifted.append(ei + off)   # shift both rows\n",
    "    Aei_batch = torch.cat(Aei_shifted, dim=1)   # (2 , E_tot)\n",
    "\n",
    "    Aef_batch = concat_csr(aef)\n",
    "\n",
    "    # ----- merge label edges -------------------------------------\n",
    "    Lei_shifted = []\n",
    "    for off, ei in zip(node_offsets, lei):\n",
    "        Lei_shifted.append(ei + off)\n",
    "    Lei_batch = torch.cat(Lei_shifted, dim=1)\n",
    "\n",
    "    Lef_batch = concat_csr(lef)\n",
    "    y_batch   = torch.cat(ys)\n",
    "\n",
    "    node_sizes = [x.size(0) for x in xs]\n",
    "    node_ptr = torch.zeros(len(node_sizes) + 1, dtype=torch.long)\n",
    "    node_ptr[1:] = torch.tensor(node_sizes, dtype=torch.long).cumsum(0)\n",
    "    title_idx_local = torch.tensor(titleIdxs, dtype=torch.long)\n",
    "\n",
    "    return filenames, X_batch, Aei_batch, Aef_batch, Lei_batch, Lef_batch, y_batch, node_ptr, title_idx_local\n",
    "\n",
    "def debug_collate(batch):\n",
    "    _, xs, aei, aef, lei, lef, ys = zip(*batch)\n",
    "    print(\"--- one mini-batch ---\")\n",
    "    for i, X in enumerate(xs):\n",
    "        print(f\"graph {i}:  nodes={X.size(0):4d}   \"\n",
    "              f\"struct-edges={aei[i].shape[1]:4d}   \"\n",
    "              f\"label-edges={lei[i].shape[1]:3d}\")\n",
    "    # then call the real collate to keep training code unchanged\n",
    "    return sparse_graph_collate(batch)\n",
    "\n",
    "# ───────────────────────────────────────────────────────── loader utilities\n",
    "def identity_collate(batch):\n",
    "    \"\"\"batch == list of length 1 → return that single sample untouched.\"\"\"\n",
    "    return batch[0]\n",
    "\n",
    "def make_loader(ds, batch_size=1, shuffle=False):\n",
    "    return DataLoader(ds,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      collate_fn=sparse_graph_collate,\n",
    "                      num_workers=0,\n",
    "                      pin_memory=True)    # fast GPU transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0048a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_live(\n",
    "    edgetrain_vals,\n",
    "    titletrain_vals,\n",
    "    totaltrain_vals,\n",
    "    val_vals,\n",
    "    p, r, f1,                 # new metric lists (same length as train/val)\n",
    "    save_path,\n",
    "    xlabel=\"Epoch\",\n",
    "    ylabel_left=\"Loss / Accuracy\",\n",
    "    ylabel_right=\"P · R · F1\",\n",
    "    title=\"Training progress\",\n",
    "    fig_ax=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Live-updating dual-axis plot.\n",
    "    Call once per epoch with the (growing) metric lists.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_vals, val_vals : list[float]\n",
    "        Main metric to compare (e.g. loss or accuracy).\n",
    "    p, r, f1 : list[float]\n",
    "        Precision, recall, f1 – plotted on a secondary y-axis.\n",
    "    save_path : str or Path\n",
    "        Where to write the PNG each time.\n",
    "    fig_ax : tuple(fig, (ax_left, ax_right)) | None\n",
    "        Pass back what you got from the previous call to avoid flicker.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (fig, (ax_left, ax_right))\n",
    "        Feed this straight back into the next call.\n",
    "    \"\"\"\n",
    "    # ---------- figure / axes boilerplate ----------\n",
    "    if fig_ax is None:\n",
    "        fig, ax_left = plt.subplots(figsize=(8, 5))\n",
    "        ax_right = ax_left.twinx()\n",
    "    else:\n",
    "        fig, (ax_left, ax_right) = fig_ax\n",
    "\n",
    "    # ---------- clear and redraw ----------\n",
    "    ax_left.cla()\n",
    "    ax_right.cla()\n",
    "\n",
    "    epochs = range(1, len(totaltrain_vals) + 1)\n",
    "\n",
    "    # left-axis curves\n",
    "    ax_left.plot(epochs, edgetrain_vals, \"-o\", label=\"Edge Train\", markersize=4)\n",
    "    ax_left.plot(epochs, titletrain_vals, \"-o\", label=\"Title Train\", markersize=4)\n",
    "    ax_left.plot(epochs, totaltrain_vals, \"-o\", label=\"Total Train\", markersize=4)\n",
    "    ax_left.plot(epochs, val_vals,   \"-s\", label=\"Val\",   markersize=4)\n",
    "    ax_left.set_xlabel(xlabel)\n",
    "    ax_left.set_ylabel(ylabel_left)\n",
    "    ax_left.grid(True, axis=\"both\")\n",
    "\n",
    "    # right-axis curves\n",
    "    ax_right.plot(epochs, p,  \"--d\", label=\"Precision\", markersize=4)\n",
    "    ax_right.plot(epochs, r,  \"--^\", label=\"Recall\",    markersize=4)\n",
    "    ax_right.plot(epochs, f1, \"--*\", label=\"F1\",        markersize=4)\n",
    "    ax_right.set_ylabel(ylabel_right)\n",
    "\n",
    "    # one combined legend\n",
    "    lines_l, labels_l = ax_left.get_legend_handles_labels()\n",
    "    lines_r, labels_r = ax_right.get_legend_handles_labels()\n",
    "    ax_left.legend(lines_l + lines_r, labels_l + labels_r, loc=\"upper center\", ncol=5)\n",
    "\n",
    "    ax_left.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(Path(save_path), dpi=150)\n",
    "\n",
    "    return fig, (ax_left, ax_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ddb1095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_graph_title_loss(title_logits, node_ptr, title_idx_local):\n",
    "    \"\"\"\n",
    "    title_logits: 1D scores per node across the whole batch [N_total]\n",
    "    node_ptr:     [G+1] cumulative node counts; graph g = [s:e)\n",
    "    title_idx_local: [G] local index (0..N_g-1) of gold title per graph\n",
    "    \"\"\"\n",
    "    G = node_ptr.numel() - 1\n",
    "    if G <= 0:\n",
    "        return title_logits.new_zeros((), dtype=torch.float32)\n",
    "\n",
    "    losses = []\n",
    "    for g in range(G):\n",
    "        s = int(node_ptr[g].item()); e = int(node_ptr[g+1].item())\n",
    "        if e <= s:  # empty graph guard\n",
    "            continue\n",
    "        logits_g = title_logits[s:e]              # [N_g]\n",
    "        # OUT-OF-PLACE clamp (no `_`)\n",
    "        tgt = torch.clamp(title_idx_local[g], 0, (e - s) - 1)\n",
    "        # CE expects [1, C] vs [1]\n",
    "        losses.append(F.cross_entropy(logits_g.unsqueeze(0), tgt.unsqueeze(0)))\n",
    "    return torch.stack(losses).mean() if losses else title_logits.new_zeros(())\n",
    "\n",
    "\n",
    "\n",
    "def focal_loss(logits, targets, alpha = 0.25, gamma = 2.0, reduction: str = \"mean\"):\n",
    "    bce = F.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n",
    "    p_t = torch.exp(-bce)          # = σ(z) if y==1 else 1-σ(z)\n",
    "    loss = (alpha * (1.0 - p_t).pow(gamma) * bce)\n",
    "    return loss.mean() if reduction == \"mean\" else loss.sum()\n",
    "\n",
    "\n",
    "# ---------- 2. Pair-wise AUC (logistic ranking) loss -------------------------\n",
    "def pairwise_auc_loss(logits, targets, sample_k: int | None = None):\n",
    "    \"\"\"\n",
    "    logits   : float tensor (B,)\n",
    "    targets  : {0,1} tensor (B,)\n",
    "    sample_k : optional int – #negatives to sample per positive.  If None,\n",
    "               uses *all* positives × negatives (can be heavy for big batches).\n",
    "    \"\"\"\n",
    "    pos_logits = logits[targets == 1]      # shape (P,)\n",
    "    neg_logits = logits[targets == 0]      # shape (N,)\n",
    "\n",
    "    if pos_logits.numel() == 0 or neg_logits.numel() == 0:\n",
    "        # No valid pairs (edge cases in small batches) – return 0 so it\n",
    "        # doesn't break the graph.\n",
    "        return logits.new_tensor(0.0, requires_grad=True)\n",
    "\n",
    "    # --- optional negative subsampling to save memory ---\n",
    "    if sample_k is not None and neg_logits.numel() > sample_k:\n",
    "        idx = torch.randperm(neg_logits.numel(), device=logits.device)[:sample_k]\n",
    "        neg_logits = neg_logits[idx]\n",
    "\n",
    "    # Broadcast positives against negatives: diff = s_pos - s_neg\n",
    "    diff = pos_logits[:, None] - neg_logits[None, :]        # (P, N) or (P, k)\n",
    "    loss = F.softplus(-diff)                                # log(1+e^(-diff))\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "# ---------- 3. Combined wrapper ----------------------------------------------\n",
    "class PairwiseAUCFocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    total_loss = pairwise_auc_loss + lambda_focal * focal_loss\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 gamma: float = 2.0,\n",
    "                 alpha: float = 0.25,\n",
    "                 lambda_focal: float = 0.5,\n",
    "                 sample_k: int | None = None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.lambda_focal = lambda_focal\n",
    "        self.sample_k = sample_k\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        loss_rank = pairwise_auc_loss(\n",
    "            logits, targets, sample_k=self.sample_k\n",
    "        )\n",
    "        loss_focal = focal_loss(\n",
    "            logits, targets, alpha=self.alpha, gamma=self.gamma\n",
    "        )\n",
    "        return loss_rank * (1 - self.lambda_focal) + self.lambda_focal * loss_focal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96e35002",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_NORM = 2.0           # gradient clipping\n",
    "\n",
    "# ---------- one epoch --------------------------------------------------------\n",
    "def train_epoch(model, loader, optimizer,\n",
    "                criterion, sched, epoch, totalEpoch, device=\"cpu\", **kwargs):\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    # running_loss, running_edges = 0.0, 0\n",
    "    count = 0\n",
    "    edge_loss_num = 0.0   # sum over edges of per-edge loss\n",
    "    edge_count    = 0\n",
    "    title_loss_num = 0.0  # sum over graphs of per-graph loss\n",
    "    graph_count    = 0\n",
    "    l = len(loader)\n",
    "\n",
    "    for f, X_sparse, Aei, Aef, Lei, Lef, y, node_ptr, title_idx_local in loader:\n",
    "        count += 1\n",
    "        X_sparse, Aei, Aef = X_sparse.to(device), Aei.to(device), Aef.to(device)\n",
    "        Lei, Lef, y = Lei.to(device), Lef.to(device), y.to(device)\n",
    "        node_ptr, title_idx_local = node_ptr.to(device), title_idx_local.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        edge_logits, title_logits = model(X_sparse, Aei, Aef, Lei, Lef, kwargs[\"p_Lef_drop\"], kwargs[\"use_E_attr\"], kwargs[\"use_A_attr\"], return_title=True)          # (N_label,)\n",
    "\n",
    "         # --- Edge loss: normalize per-edge (sum / num_edges) ---\n",
    "        num_edges = int(y.numel())\n",
    "        edge_loss_sum = F.binary_cross_entropy_with_logits(edge_logits, y.float(), reduction=\"sum\")\n",
    "        edge_loss = edge_loss_sum / max(num_edges, 1)\n",
    "\n",
    "        # --- Title loss: mean per-graph ---\n",
    "        G = int(node_ptr.numel() - 1)\n",
    "        title_loss = per_graph_title_loss(title_logits, node_ptr, title_idx_local)\n",
    "\n",
    "        # --- Total loss ---\n",
    "        loss = edge_loss + kwargs[\"lambda_title\"] * title_loss\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "        optimizer.step()\n",
    "        sched.step()\n",
    "\n",
    "        edge_loss_num  += float(edge_loss.item())  * num_edges  # back to \"sum over edges\"\n",
    "        edge_count     += num_edges\n",
    "        title_loss_num += float(title_loss.item()) * max(G, 0)  # sum over graphs\n",
    "        graph_count    += max(G, 0)\n",
    "\n",
    "        if count % 20 == 0:\n",
    "            print(f\"epoch {count}/{l} \"\n",
    "                    f\"edge_loss={edge_loss:.4f}, title_loss={(kwargs[\"lambda_title\"] * title_loss):.4f}, loss={loss:.4f}\")\n",
    "\n",
    "    avg_edge  = edge_loss_num / max(edge_count, 1)\n",
    "    avg_title = title_loss_num / max(graph_count, 1)\n",
    "    avg_total = avg_edge + kwargs[\"lambda_title\"] * avg_title\n",
    "    return avg_edge, avg_title, avg_total\n",
    "\n",
    "\n",
    "# ---------- evaluation -------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def eval_edge_model(model, loader, criterion, device=\"cpu\", thr_type=\"median\", **kwargs):\n",
    "    model.eval()\n",
    "    TP = FP = FN = 0\n",
    "    TP2 = FP2 = FN2 = 0\n",
    "    running_loss, running_edges = 0.0, 0\n",
    "\n",
    "    filenames = []\n",
    "    for f, X_sparse, Aei, Aef, Lei, Lef, y, node_ptr, title_idx_local in loader:\n",
    "        filenames += f\n",
    "        X_sparse, Aei, Aef = X_sparse.to(device), Aei.to(device), Aef.to(device)\n",
    "        Lei, Lef, y = Lei.to(device), Lef.to(device), y.to(device)\n",
    "        node_ptr, title_idx_local = node_ptr.to(device), title_idx_local.to(device)\n",
    "\n",
    "        #Complete Model\n",
    "        edge_logits, title_logits = model(X_sparse, Aei, Aef, Lei, Lef, 0, kwargs[\"use_E_attr\"], kwargs[\"use_A_attr\"], return_title=True)\n",
    "        edge_loss  = criterion(edge_logits, y.float())\n",
    "        title_loss = per_graph_title_loss(title_logits, node_ptr, title_idx_local)\n",
    "        loss = edge_loss + kwargs[\"lambda_title\"] * title_loss\n",
    "        running_loss  += loss.item() * y.numel()\n",
    "        running_edges += y.numel()\n",
    "        probs  = torch.sigmoid(edge_logits)\n",
    "        if thr_type==\"median\":\n",
    "            thr = torch.median(probs)\n",
    "\n",
    "        pred = (probs >= thr).long()\n",
    "        TP  += ((pred == 1) & (y == 1)).sum().item()\n",
    "        FP  += ((pred == 1) & (y == 0)).sum().item()\n",
    "        FN  += ((pred == 0) & (y == 1)).sum().item()\n",
    "\n",
    "    print(f\"Validating {np.unique([filename[:-5] for filename in filenames])} website type\")\n",
    "    \n",
    "    prec = TP / (TP + FP + 1e-9)\n",
    "    rec  = TP / (TP + FN + 1e-9)\n",
    "    f1   = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "    return running_loss / running_edges, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67146255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                load_checkpoint,\n",
    "                num_epochs     = 100,\n",
    "                lr             = 1e-3,\n",
    "                validate_every = 10,\n",
    "                patience       = 10,\n",
    "                device         = \"cpu\"):\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    model_path = \"./model_in_training.pt\"\n",
    "    if os.path.exists(model_path) and load_checkpoint:\n",
    "        print(\"loading existing model...\")\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    opt   = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    sched = lr_scheduler.OneCycleLR(opt, max_lr=4e-4, epochs=num_epochs, steps_per_epoch=len(train_loader),\n",
    "                   pct_start=0.1, anneal_strategy='cos', div_factor=25, final_div_factor=1e4, cycle_momentum=False)\n",
    "                        #StepLR(opt, step_size=3, gamma=0.9)\n",
    "    criterion = focal_loss\n",
    "    # criterion = PairwiseAUCFocalLoss(\n",
    "    #             gamma=2.0,\n",
    "    #             alpha=0.25,\n",
    "    #             lambda_focal=1,  # 0 ⇒ pure ranking loss; 1 ⇒ equal weight\n",
    "    #             sample_k=128     # speeds up training; set None for exact loss\n",
    "    #         )\n",
    "    #criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_f1, fig_ax, best_state = 0.0, None, None\n",
    "    edgetrain_loss, titletrain_loss, totaltrain_loss, val_loss, precision, recall, f1score = [], [], [], [], [], [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        lambda_title = 0.01 - 0.01*(epoch/num_epochs) if epoch > 0 else 0\n",
    "        p_Lef_drop = 0#.3 - 0.3 * (epoch-2)/(num_epochs-2 + 1e-9)        \n",
    "        use_E_attr,  use_A_attr = (epoch>0), (epoch>0)\n",
    "\n",
    "        edgeloss, titleloss, totalloss = train_epoch(model, train_loader, opt, criterion, sched, epoch, num_epochs, device=device, use_E_attr=use_E_attr, use_A_attr = use_A_attr, p_Lef_drop = p_Lef_drop, lambda_title=lambda_title)\n",
    "        edgetrain_loss.append(edgeloss)\n",
    "        titletrain_loss.append(titleloss)\n",
    "        totaltrain_loss.append(totalloss)\n",
    "\n",
    "        if epoch % validate_every == 0 or epoch == num_epochs:\n",
    "            loss, p, r, f1 = eval_edge_model(model, val_loader, criterion, device=device, use_E_attr=use_E_attr, use_A_attr = use_A_attr, lambda_title=lambda_title)\n",
    "            val_loss.append(loss)\n",
    "\n",
    "            lr_now = opt.param_groups[0][\"lr\"]\n",
    "            print(f\"Epoch {epoch:03d}/{num_epochs} \"\n",
    "                  f\"loss={loss:.4f}  P={p:.3f} R={r:.3f} F1={f1:.3f}  lr={lr_now:.2e}  E_features={use_E_attr} A_features={use_A_attr}\")\n",
    "            precision.append(p)\n",
    "            recall.append(r)\n",
    "            f1score.append(f1)\n",
    "\n",
    "            if f1 >= best_f1:\n",
    "                best_f1, best_state = f1, copy.deepcopy(model.state_dict())\n",
    "\n",
    "            # if lr_now < 1e-5:\n",
    "            #     print(\"Stop: LR < 1e-5\")\n",
    "            #     break\n",
    "\n",
    "            fig_ax = plot_metrics_live(\n",
    "                edgetrain_loss, titletrain_loss, totaltrain_loss,\n",
    "                val_loss,\n",
    "                precision,recall,f1score,\n",
    "                \"CurrentRun\",\n",
    "                xlabel=\"Epoch\",\n",
    "                ylabel_left=\"Loss\",\n",
    "                ylabel_right=\"P · R · F1\",\n",
    "                title=\"Model Performance\",\n",
    "                fig_ax=fig_ax\n",
    "            )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return best_state, train_loss, val_loss, fig_ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbfe9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TarGraphDataset(datafile)\n",
    "N = len(dataset)\n",
    "# n_train = int(0.95 * N)\n",
    "# n_val   = N - n_train\n",
    "# train_ds, val_ds = random_split(dataset, [n_train, n_val])\n",
    "matchcollege_start, matchcollege_end = dataset.get_sublen('university-matchcollege(2000)')\n",
    "allmovie_start, allmovie_end = dataset.get_sublen('movie-allmovie(2000)')\n",
    "imdb_start, imdb_end = dataset.get_sublen('movie-imdb(2000)')\n",
    "usatoday_start, usatoday_end = dataset.get_sublen('nbaplayer-usatoday(436)')\n",
    "yahoo_start, yahoo_end = dataset.get_sublen('nbaplayer-yahoo(438)')\n",
    "matchcollege_idx = list(range(matchcollege_start, matchcollege_end))\n",
    "allmovie_idx = list(range(allmovie_start, allmovie_end))\n",
    "imdb_idx = list(range(imdb_start, imdb_end))\n",
    "usatoday_idx=list(range(usatoday_start, usatoday_end))\n",
    "yahoo_idx=list(range(yahoo_start, yahoo_end))\n",
    "\n",
    "val_idx = list(set(allmovie_idx))#list(set(matchcollege_idx[-10:])) + list(set(allmovie_idx[-10:]))#\n",
    "train_idx = list(set(range(N)) - set(val_idx) - set(usatoday_idx) - set(yahoo_idx))#list(set(matchcollege_idx + allmovie_idx) - set(val_idx))#\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds   = Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = make_loader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = make_loader(val_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "model = GraphAttentionNetwork(in_dim = 119, edge_in_dim = 210, edge_emb_dim = 32, hidden1 = 32, hidden2 = 32, hidden3 = 8, heads = 2)#16,32,4 was the winner\n",
    "\n",
    "load_checkpoint = False\n",
    "_, trainloss, valloss, fig_ax = train_model(model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            load_checkpoint,\n",
    "            num_epochs     = 29,\n",
    "            lr             = 1e-3,\n",
    "            validate_every = 1,\n",
    "            patience       = 1,\n",
    "            device         = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc1814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "torch.save(model.state_dict(), \"FULLTRAINEDALLDATAModelf1--newtagsandtitle.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d59625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating ['swde_HTMLgraphs/movie/movie/movie-allmovie(2000)'] website type\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.04156546794519418,\n",
       " 0.7552735881680096,\n",
       " 0.7551079869696979,\n",
       " 0.7551907779904338)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_path = \"./FULLTRAINEDALLDATAModelf1-74-learning.pt\"\n",
    "# if os.path.exists(model_path) and load_checkpoint:\n",
    "#     print(\"loading existing model...\")\n",
    "#     model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "\n",
    "eval_edge_model(model, val_loader, focal_loss, device=\"cuda\", use_E_attr=True, use_A_attr=True)\n",
    "#b4 submitting to A100\n",
    "#Experiemnt with the comparison loss\n",
    "#Do self layers myself\n",
    "#\n",
    "#Graphs of also without edges\n",
    "\n",
    "#32 32 layers\n",
    "#Just train everything from the start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
