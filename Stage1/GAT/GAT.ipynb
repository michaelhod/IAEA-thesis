{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff77184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from torch.optim import lr_scheduler\n",
    "from scipy import sparse\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "import io, tarfile, os\n",
    "import copy\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits as BCEwLogits\n",
    "from GATModel import GraphAttentionNetwork\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.current_device()\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "datafile = \"../../data/swde_HTMLgraphsNEWFEATURES.tar\"\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562900ca",
   "metadata": {},
   "source": [
    "***BELOW***\n",
    "If data-loading < 5-10 % of total epoch time with num_workers=0, stick with the simple path.\n",
    "Otherwise, parallel loading with share-friendly torch_sparse.SparseTensor\n",
    "almost always pays off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fd8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────── Tar-reader dataset\n",
    "class TarGraphDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each graph is stored under its own sub-directory *inside* one .tar:\n",
    "\n",
    "        graphs.tar\n",
    "        ├── 0001/X.npz\n",
    "        ├── 0001/E.npz\n",
    "        ├── 0001/edge_index.npy\n",
    "        ├── 0001/labels.npz\n",
    "        ├── 0001/label_index.npy\n",
    "        ├── 0001/label_value.npy\n",
    "        ├── 0002/…\n",
    "        └── …\n",
    "\n",
    "    The tar is opened once; __getitem__ streams the six files for graph *idx*\n",
    "    straight into memory, converts them to native PyTorch tensors and returns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tar_path: str | Path):\n",
    "        self.tar = tarfile.open(tar_path, mode=\"r:*\")      # gzip/none/…\n",
    "        self.index: dict[str, dict[str, tarfile.TarInfo]] = {}\n",
    "        self.sublen = {}\n",
    "\n",
    "        # Build a small lookup table in RAM  {gid: {filename: tarinfo}}\n",
    "        for member in self.tar.getmembers():\n",
    "            if not member.isfile():\n",
    "                continue\n",
    "\n",
    "            p     = Path(member.name)\n",
    "            gid   = str(p.parent)   # '0007'\n",
    "            fname = p.name          # 'X.npz'\n",
    "\n",
    "            # keep only folders that really are 4-digit graph IDs\n",
    "            if gid[-4:].isdigit():\n",
    "                self.index.setdefault(gid, {})[fname] = member\n",
    "\n",
    "        self.gids = sorted(self.index)\n",
    "\n",
    "        # Remove thos with no labels\n",
    "        for gid, files in self.index.items():\n",
    "            if not files.get(\"labels.npz\"):\n",
    "                self.gids.remove(gid)\n",
    "\n",
    "        # Count\n",
    "        name, counts = np.unique([Path(gid).parent.name for gid in self.gids], return_counts=True)\n",
    "\n",
    "        # Get cumsum\n",
    "        running = 0\n",
    "        for lbl, cnt in zip(name, counts):\n",
    "            self.sublen[lbl] = (running, running + cnt)\n",
    "            running += cnt\n",
    "\n",
    "    # ------------- helpers --------------------------------------------------\n",
    "    @staticmethod\n",
    "    def _npz_to_csr(buf: bytes, dtype=torch.float32):\n",
    "        csr = sparse.load_npz(io.BytesIO(buf)).tocsr()\n",
    "        crow = torch.from_numpy(csr.indptr.astype(np.int64))\n",
    "        col  = torch.from_numpy(csr.indices.astype(np.int64))\n",
    "        val  = torch.from_numpy(csr.data).to(dtype)\n",
    "        return torch.sparse_csr_tensor(\n",
    "            crow, col, val, size=csr.shape, dtype=dtype, requires_grad=False\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _npy_to_tensor(buf: bytes, dtype):\n",
    "        arr = np.load(io.BytesIO(buf), allow_pickle=False)\n",
    "        return torch.from_numpy(arr).to(dtype)\n",
    "\n",
    "    def get_sublen(self, name):\n",
    "        return self.sublen[name]\n",
    "\n",
    "    # ------------- Dataset API ---------------------------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.gids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gid   = self.gids[idx]\n",
    "        files = self.index[gid]\n",
    "\n",
    "        get = lambda name: self.tar.extractfile(files[name]).read()\n",
    "        \n",
    "        fileinfo = gid\n",
    "\n",
    "        X   = self._npz_to_csr(get(\"X.npz\"),       dtype=torch.float32)\n",
    "        Aef = self._npz_to_csr(get(\"E.npz\"),       dtype=torch.float32)\n",
    "        Lef = self._npz_to_csr(get(\"labels.npz\"),  dtype=torch.float32)\n",
    "\n",
    "        Aei = self._npy_to_tensor(get(\"edge_index.npy\"),  dtype=torch.int64)\n",
    "        Lei = self._npy_to_tensor(get(\"label_index.npy\"), dtype=torch.int64)\n",
    "        y   = self._npy_to_tensor(get(\"label_value.npy\"), dtype=torch.int64)\n",
    "\n",
    "        return fileinfo, X, Aei.t().contiguous(), Aef, Lei.t().contiguous(), Lef, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "316ad981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_csr(blocks):\n",
    "    \"\"\"\n",
    "    Vertically stack CSR matrices that all share the same n_cols.\n",
    "    Keeps sparsity and returns a single torch.sparse_csr_tensor.\n",
    "    \"\"\"\n",
    "    crow_bufs, col_bufs, val_bufs = [], [], []\n",
    "    nnz_so_far, n_rows, n_cols = 0, 0, blocks[0].size(1)\n",
    "\n",
    "    for k, csr in enumerate(blocks):\n",
    "        crow = csr.crow_indices().clone()          # (n_rows_k + 1,)\n",
    "\n",
    "        # 1) shift by *cumulative* nnz so far\n",
    "        crow += nnz_so_far\n",
    "\n",
    "        # 2) drop the leading 0 for every block after the first\n",
    "        if k > 0:\n",
    "            crow = crow[1:]\n",
    "\n",
    "        crow_bufs.append(crow)\n",
    "        col_bufs.append(csr.col_indices())\n",
    "        val_bufs.append(csr.values())\n",
    "\n",
    "        nnz_so_far += csr.values().numel()\n",
    "        n_rows     += csr.size(0)\n",
    "\n",
    "    crow_cat = torch.cat(crow_bufs)\n",
    "    col_cat  = torch.cat(col_bufs)\n",
    "    val_cat  = torch.cat(val_bufs)\n",
    "\n",
    "    return torch.sparse_csr_tensor(\n",
    "        crow_cat, col_cat, val_cat,\n",
    "        size=(n_rows, n_cols),\n",
    "        dtype=val_cat.dtype,\n",
    "        device=val_cat.device,\n",
    "        requires_grad=False\n",
    "    )\n",
    "\n",
    "\n",
    "def sparse_graph_collate(batch):\n",
    "    # unpack each graph\n",
    "    filenames, xs, aei, aef, lei, lef, ys = zip(*batch)\n",
    "\n",
    "    # node-count prefix sum for shifting\n",
    "    node_offsets = torch.cumsum(\n",
    "        torch.tensor([0] + [x.size(0) for x in xs[:-1]]), 0)\n",
    "\n",
    "    # ----- merge node features (CSR) -----------------------------\n",
    "    X_batch = concat_csr(xs)\n",
    "\n",
    "    # ----- merge structural edges --------------------------------\n",
    "    Aei_shifted = []\n",
    "    for off, ei in zip(node_offsets, aei):\n",
    "        Aei_shifted.append(ei + off)   # shift both rows\n",
    "    Aei_batch = torch.cat(Aei_shifted, dim=1)   # (2 , E_tot)\n",
    "\n",
    "    Aef_batch = concat_csr(aef)\n",
    "\n",
    "    # ----- merge label edges -------------------------------------\n",
    "    Lei_shifted = []\n",
    "    for off, ei in zip(node_offsets, lei):\n",
    "        Lei_shifted.append(ei + off)\n",
    "    Lei_batch = torch.cat(Lei_shifted, dim=1)\n",
    "\n",
    "    Lef_batch = concat_csr(lef)\n",
    "    y_batch   = torch.cat(ys)\n",
    "\n",
    "    return filenames, X_batch, Aei_batch, Aef_batch, Lei_batch, Lef_batch, y_batch\n",
    "\n",
    "def debug_collate(batch):\n",
    "    _, xs, aei, aef, lei, lef, ys = zip(*batch)\n",
    "    print(\"--- one mini-batch ---\")\n",
    "    for i, X in enumerate(xs):\n",
    "        print(f\"graph {i}:  nodes={X.size(0):4d}   \"\n",
    "              f\"struct-edges={aei[i].shape[1]:4d}   \"\n",
    "              f\"label-edges={lei[i].shape[1]:3d}\")\n",
    "    # then call the real collate to keep training code unchanged\n",
    "    return sparse_graph_collate(batch)\n",
    "\n",
    "# ───────────────────────────────────────────────────────── loader utilities\n",
    "def identity_collate(batch):\n",
    "    \"\"\"batch == list of length 1 → return that single sample untouched.\"\"\"\n",
    "    return batch[0]\n",
    "\n",
    "def make_loader(ds, batch_size=1, shuffle=False):\n",
    "    return DataLoader(ds,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      collate_fn=sparse_graph_collate,\n",
    "                      num_workers=0,\n",
    "                      pin_memory=True)    # fast GPU transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0048a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_live(\n",
    "    train_vals,\n",
    "    val_vals,\n",
    "    p, r, f1,                 # new metric lists (same length as train/val)\n",
    "    save_path,\n",
    "    xlabel=\"Epoch\",\n",
    "    ylabel_left=\"Loss / Accuracy\",\n",
    "    ylabel_right=\"P · R · F1\",\n",
    "    title=\"Training progress\",\n",
    "    fig_ax=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Live-updating dual-axis plot.\n",
    "    Call once per epoch with the (growing) metric lists.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_vals, val_vals : list[float]\n",
    "        Main metric to compare (e.g. loss or accuracy).\n",
    "    p, r, f1 : list[float]\n",
    "        Precision, recall, f1 – plotted on a secondary y-axis.\n",
    "    save_path : str or Path\n",
    "        Where to write the PNG each time.\n",
    "    fig_ax : tuple(fig, (ax_left, ax_right)) | None\n",
    "        Pass back what you got from the previous call to avoid flicker.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (fig, (ax_left, ax_right))\n",
    "        Feed this straight back into the next call.\n",
    "    \"\"\"\n",
    "    # ---------- figure / axes boilerplate ----------\n",
    "    if fig_ax is None:\n",
    "        fig, ax_left = plt.subplots(figsize=(8, 5))\n",
    "        ax_right = ax_left.twinx()\n",
    "    else:\n",
    "        fig, (ax_left, ax_right) = fig_ax\n",
    "\n",
    "    # ---------- clear and redraw ----------\n",
    "    ax_left.cla()\n",
    "    ax_right.cla()\n",
    "\n",
    "    epochs = range(1, len(train_vals) + 1)\n",
    "\n",
    "    # left-axis curves\n",
    "    ax_left.plot(epochs, train_vals, \"-o\", label=\"Train\", markersize=4)\n",
    "    ax_left.plot(epochs, val_vals,   \"-s\", label=\"Val\",   markersize=4)\n",
    "    ax_left.set_xlabel(xlabel)\n",
    "    ax_left.set_ylabel(ylabel_left)\n",
    "    ax_left.grid(True, axis=\"both\")\n",
    "\n",
    "    # right-axis curves\n",
    "    ax_right.plot(epochs, p,  \"--d\", label=\"Precision\", markersize=4)\n",
    "    ax_right.plot(epochs, r,  \"--^\", label=\"Recall\",    markersize=4)\n",
    "    ax_right.plot(epochs, f1, \"--*\", label=\"F1\",        markersize=4)\n",
    "    ax_right.set_ylabel(ylabel_right)\n",
    "\n",
    "    # one combined legend\n",
    "    lines_l, labels_l = ax_left.get_legend_handles_labels()\n",
    "    lines_r, labels_r = ax_right.get_legend_handles_labels()\n",
    "    ax_left.legend(lines_l + lines_r, labels_l + labels_r, loc=\"upper center\", ncol=5)\n",
    "\n",
    "    ax_left.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(Path(save_path), dpi=150)\n",
    "\n",
    "    return fig, (ax_left, ax_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb1095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(logits, targets, alpha = 0.25, gamma = 2.0, reduction: str = \"mean\"):\n",
    "    bce = F.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n",
    "    p_t = torch.exp(-bce)          # = σ(z) if y==1 else 1-σ(z)\n",
    "    loss = (alpha * (1.0 - p_t).pow(gamma) * bce)\n",
    "    return loss.mean() if reduction == \"mean\" else loss.sum()\n",
    "\n",
    "\n",
    "# ---------- 2. Pair-wise AUC (logistic ranking) loss -------------------------\n",
    "def pairwise_auc_loss(logits, targets, sample_k: int | None = None):\n",
    "    \"\"\"\n",
    "    logits   : float tensor (B,)\n",
    "    targets  : {0,1} tensor (B,)\n",
    "    sample_k : optional int – #negatives to sample per positive.  If None,\n",
    "               uses *all* positives × negatives (can be heavy for big batches).\n",
    "    \"\"\"\n",
    "    pos_logits = logits[targets == 1]      # shape (P,)\n",
    "    neg_logits = logits[targets == 0]      # shape (N,)\n",
    "\n",
    "    if pos_logits.numel() == 0 or neg_logits.numel() == 0:\n",
    "        # No valid pairs (edge cases in small batches) – return 0 so it\n",
    "        # doesn't break the graph.\n",
    "        return logits.new_tensor(0.0, requires_grad=True)\n",
    "\n",
    "    # --- optional negative subsampling to save memory ---\n",
    "    if sample_k is not None and neg_logits.numel() > sample_k:\n",
    "        idx = torch.randperm(neg_logits.numel(), device=logits.device)[:sample_k]\n",
    "        neg_logits = neg_logits[idx]\n",
    "\n",
    "    # Broadcast positives against negatives: diff = s_pos - s_neg\n",
    "    diff = pos_logits[:, None] - neg_logits[None, :]        # (P, N) or (P, k)\n",
    "    loss = F.softplus(-diff)                                # log(1+e^(-diff))\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "# ---------- 3. Combined wrapper ----------------------------------------------\n",
    "class PairwiseAUCFocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    total_loss = pairwise_auc_loss + lambda_focal * focal_loss\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 gamma: float = 2.0,\n",
    "                 alpha: float = 0.25,\n",
    "                 lambda_focal: float = 0.5,\n",
    "                 sample_k: int | None = None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.lambda_focal = lambda_focal\n",
    "        self.sample_k = sample_k\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        loss_rank = pairwise_auc_loss(\n",
    "            logits, targets, sample_k=self.sample_k\n",
    "        )\n",
    "        loss_focal = focal_loss(\n",
    "            logits, targets, alpha=self.alpha, gamma=self.gamma\n",
    "        )\n",
    "        return loss_rank * (1 - self.lambda_focal) + self.lambda_focal * loss_focal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e35002",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_NORM = 2.0           # gradient clipping\n",
    "\n",
    "# ---------- one epoch --------------------------------------------------------\n",
    "def train_epoch(model, loader, optimizer,\n",
    "                criterion, epoch, totalEpoch, device=\"cpu\", **kwargs):\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    running_loss, running_edges = 0.0, 0\n",
    "    count = 0\n",
    "    l = len(loader)\n",
    "\n",
    "    for f, X_sparse, Aei, Aef, Lei, Lef, y in loader:\n",
    "        count += 1\n",
    "        X_sparse, Aei, Aef = X_sparse.to(device), Aei.to(device), Aef.to(device)\n",
    "        Lei, Lef, y = Lei.to(device), Lef.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(X_sparse, Aei, Aef, Lei, Lef, kwargs[\"p_Lef_drop\"], kwargs[\"use_E_attr\"], kwargs[\"use_A_attr\"])          # (N_label,)\n",
    "        loss   = criterion(logits, y.float())\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss  += loss.item() * y.numel()\n",
    "        running_edges += y.numel()\n",
    "\n",
    "        if count % 20 == 0:\n",
    "            print(f\"epoch {count}/{l} \"\n",
    "                    f\"loss={loss:.4f}\")\n",
    "\n",
    "            # loss, p, r, f1 = eval_edge_model(model, val_loader, criterion, device=device, use_E_attr=kwargs[\"use_E_attr\"], use_A_attr = kwargs[\"use_A_attr\"])\n",
    "            # print(f\"\\t\\tloss={loss:.4f}  P={p:.3f} R={r:.3f} F1={f1:.3f}  E_features={kwargs[\"use_E_attr\"]} A_features={kwargs[\"use_A_attr\"]}\")\n",
    "\n",
    "    return running_loss / running_edges\n",
    "\n",
    "\n",
    "# ---------- evaluation -------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def eval_edge_model(model, loader, criterion, device=\"cpu\", thr_type=\"median\", **kwargs):\n",
    "    model.eval()\n",
    "    TP = FP = FN = 0\n",
    "    TP2 = FP2 = FN2 = 0\n",
    "    running_loss, running_edges = 0.0, 0\n",
    "\n",
    "    filenames = []\n",
    "    for f, X_sparse, Aei, Aef, Lei, Lef, y in loader:\n",
    "        filenames += f\n",
    "        X_sparse, Aei, Aef = X_sparse.to(device), Aei.to(device), Aef.to(device)\n",
    "        Lei, Lef, y = Lei.to(device), Lef.to(device), y.to(device)\n",
    "\n",
    "        #Complete Model\n",
    "        logits = model(X_sparse, Aei, Aef, Lei, Lef, 0, kwargs[\"use_E_attr\"], kwargs[\"use_A_attr\"])\n",
    "        loss   = criterion(logits, y.float())\n",
    "        running_loss  += loss.item() * y.numel()\n",
    "        running_edges += y.numel()\n",
    "        probs  = torch.sigmoid(logits)\n",
    "        if thr_type==\"median\":\n",
    "            thr = torch.median(probs)\n",
    "\n",
    "        pred = (probs >= thr).long()\n",
    "        TP  += ((pred == 1) & (y == 1)).sum().item()\n",
    "        FP  += ((pred == 1) & (y == 0)).sum().item()\n",
    "        FN  += ((pred == 0) & (y == 1)).sum().item()\n",
    "\n",
    "    print(f\"Validating {np.unique([filename[:-5] for filename in filenames])} website type\")\n",
    "    \n",
    "    prec = TP / (TP + FP + 1e-9)\n",
    "    rec  = TP / (TP + FN + 1e-9)\n",
    "    f1   = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "    return running_loss / running_edges, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67146255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                load_checkpoint,\n",
    "                num_epochs     = 100,\n",
    "                lr             = 1e-3,\n",
    "                validate_every = 10,\n",
    "                patience       = 10,\n",
    "                device         = \"cpu\"):\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    model_path = \"./model_in_training.pt\"\n",
    "    if os.path.exists(model_path) and load_checkpoint:\n",
    "        print(\"loading existing model...\")\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    opt   = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    sched = lr_scheduler.OneCycleLR(opt, max_lr=1e-2, epochs=num_epochs, steps_per_epoch=len(train_loader),\n",
    "                   pct_start=0.1, anneal_strategy='cos', div_factor=25, final_div_factor=1e4, cycle_momentum=False)\n",
    "                        #StepLR(opt, step_size=3, gamma=0.9)\n",
    "    criterion = focal_loss\n",
    "    # criterion = PairwiseAUCFocalLoss(\n",
    "    #             gamma=2.0,\n",
    "    #             alpha=0.25,\n",
    "    #             lambda_focal=1,  # 0 ⇒ pure ranking loss; 1 ⇒ equal weight\n",
    "    #             sample_k=128     # speeds up training; set None for exact loss\n",
    "    #         )\n",
    "    #criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_f1, fig_ax, best_state = 0.0, None, None\n",
    "    train_loss, val_loss, precision, recall, f1score = [], [], [], [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        p_Lef_drop = 0#.3 - 0.3 * (epoch-2)/(num_epochs-2 + 1e-9)        \n",
    "        use_E_attr,  use_A_attr = (epoch>0), (epoch>0)\n",
    "\n",
    "        loss = train_epoch(model, train_loader, opt, criterion, epoch, num_epochs, device=device, use_E_attr=use_E_attr, use_A_attr = use_A_attr, p_Lef_drop = p_Lef_drop)\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        if epoch % validate_every == 0 or epoch == num_epochs:\n",
    "            loss, p, r, f1 = eval_edge_model(model, val_loader, criterion, device=device, use_E_attr=use_E_attr, use_A_attr = use_A_attr)\n",
    "            val_loss.append(loss)\n",
    "            sched.step()\n",
    "\n",
    "            lr_now = opt.param_groups[0][\"lr\"]\n",
    "            print(f\"Epoch {epoch:03d}/{num_epochs} \"\n",
    "                  f\"loss={loss:.4f}  P={p:.3f} R={r:.3f} F1={f1:.3f}  lr={lr_now:.2e}  E_features={use_E_attr} A_features={use_A_attr}\")\n",
    "            precision.append(p)\n",
    "            recall.append(r)\n",
    "            f1score.append(f1)\n",
    "\n",
    "            if f1 >= best_f1:\n",
    "                best_f1, best_state = f1, copy.deepcopy(model.state_dict())\n",
    "\n",
    "            # if lr_now < 1e-5:\n",
    "            #     print(\"Stop: LR < 1e-5\")\n",
    "            #     break\n",
    "\n",
    "            fig_ax = plot_metrics_live(\n",
    "                train_loss,\n",
    "                val_loss,\n",
    "                precision,recall,f1score,\n",
    "                \"CurrentRun\",\n",
    "                xlabel=\"Epoch\",\n",
    "                ylabel_left=\"Loss\",\n",
    "                ylabel_right=\"P · R · F1\",\n",
    "                title=\"Model Performance\",\n",
    "                fig_ax=fig_ax\n",
    "            )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return best_state, train_loss, val_loss, fig_ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bbfe9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphAttentionNetwork(\n",
      "  (tr1): TransformerConv(114, 32, heads=2)\n",
      "  (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (tr2): TransformerConv(64, 32, heads=1)\n",
      "  (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "  (tr3): TransformerConv(32, 8, heads=1)\n",
      "  (edge_mlp): Sequential(\n",
      "    (0): Linear(in_features=48, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_35576\\3203468246.py:61: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:55.)\n",
      "  return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20/194 loss=0.0427\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m GraphAttentionNetwork(in_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m114\u001b[39m, edge_in_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m, edge_emb_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, hidden1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, hidden2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, hidden3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m, heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;66;03m#16,32,4 was the winner\u001b[39;00m\n\u001b[0;32m     27\u001b[0m load_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m _, trainloss, valloss, fig_ax \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_every\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 40\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, load_checkpoint, num_epochs, lr, validate_every, patience, device)\u001b[0m\n\u001b[0;32m     37\u001b[0m p_Lef_drop \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\u001b[38;5;66;03m#.3 - 0.3 * (epoch-2)/(num_epochs-2 + 1e-9)        \u001b[39;00m\n\u001b[0;32m     38\u001b[0m use_E_attr,  use_A_attr \u001b[38;5;241m=\u001b[39m (epoch\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m), (epoch\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_E_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_E_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_A_attr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_A_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_Lef_drop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp_Lef_drop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m validate_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m num_epochs:\n",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, loader, optimizer, criterion, epoch, totalEpoch, device, **kwargs)\u001b[0m\n\u001b[0;32m     10\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader)\n\u001b[1;32m---> 13\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAef\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAei\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[2], line 86\u001b[0m, in \u001b[0;36mTarGraphDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     83\u001b[0m fileinfo \u001b[38;5;241m=\u001b[39m gid\n\u001b[0;32m     85\u001b[0m X   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npz_to_csr(get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m),       dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 86\u001b[0m Aef \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_npz_to_csr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m Lef \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npz_to_csr(get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m),  dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     89\u001b[0m Aei \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_to_tensor(get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medge_index.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m),  dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n",
      "Cell \u001b[1;32mIn[2], line 57\u001b[0m, in \u001b[0;36mTarGraphDataset._npz_to_csr\u001b[1;34m(buf, dtype)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_npz_to_csr\u001b[39m(buf: \u001b[38;5;28mbytes\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32):\n\u001b[1;32m---> 57\u001b[0m     csr \u001b[38;5;241m=\u001b[39m \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_npz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtocsr()\n\u001b[0;32m     58\u001b[0m     crow \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(csr\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64))\n\u001b[0;32m     59\u001b[0m     col  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(csr\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64))\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_matrix_io.py:157\u001b[0m, in \u001b[0;36mload_npz\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown format \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msparse_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse_format \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbsr\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m((loaded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m], loaded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindices\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mloaded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindptr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m),\n\u001b[0;32m    158\u001b[0m                shape\u001b[38;5;241m=\u001b[39mloaded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sparse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdia\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m((loaded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m], loaded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m    161\u001b[0m                shape\u001b[38;5;241m=\u001b[39mloaded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:254\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\format.py:851\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    849\u001b[0m             read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[0;32m    850\u001b[0m             read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m dtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[1;32m--> 851\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m             array[i:i\u001b[38;5;241m+\u001b[39mread_count] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    853\u001b[0m                                                      count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\format.py:986\u001b[0m, in \u001b[0;36m_read_bytes\u001b[1;34m(fp, size, error_template)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 986\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    987\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:965\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m--> 965\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m    967\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1041\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_type \u001b[38;5;241m==\u001b[39m ZIP_DEFLATED:\n\u001b[0;32m   1040\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[1;32m-> 1041\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39meof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m                  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = TarGraphDataset(datafile)\n",
    "N = len(dataset)\n",
    "# n_train = int(0.95 * N)\n",
    "# n_val   = N - n_train\n",
    "# train_ds, val_ds = random_split(dataset, [n_train, n_val])\n",
    "matchcollege_start, matchcollege_end = dataset.get_sublen('university-matchcollege(2000)')\n",
    "allmovie_start, allmovie_end = dataset.get_sublen('movie-allmovie(2000)')\n",
    "imdb_start, imdb_end = dataset.get_sublen('movie-imdb(2000)')\n",
    "usatoday_start, usatoday_end = dataset.get_sublen('nbaplayer-usatoday(436)')\n",
    "yahoo_start, yahoo_end = dataset.get_sublen('nbaplayer-yahoo(438)')\n",
    "matchcollege_idx = list(range(matchcollege_start, matchcollege_end))\n",
    "allmovie_idx = list(range(allmovie_start, allmovie_end))\n",
    "imdb_idx = list(range(imdb_start, imdb_end))\n",
    "usatoday_idx=list(range(usatoday_start, usatoday_end))\n",
    "yahoo_idx=list(range(yahoo_start, yahoo_end))\n",
    "\n",
    "val_idx = list(set(allmovie_idx))#list(set(matchcollege_idx[-10:])) + list(set(allmovie_idx[-10:]))#\n",
    "train_idx = list(set(range(N)) - set(val_idx) - set(usatoday_idx) - set(yahoo_idx))#list(set(matchcollege_idx + allmovie_idx) - set(val_idx))#\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds   = Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = make_loader(train_ds, batch_size=128, shuffle=True)\n",
    "val_loader = make_loader(val_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "model = GraphAttentionNetwork(in_dim = 114, edge_in_dim = 200, edge_emb_dim = 32, hidden1 = 32, hidden2 = 32, hidden3 = 8, heads = 2)#16,32,4 was the winner\n",
    "\n",
    "load_checkpoint = False\n",
    "_, trainloss, valloss, fig_ax = train_model(model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            load_checkpoint,\n",
    "            num_epochs     = 12,\n",
    "            lr             = 1e-3,\n",
    "            validate_every = 1,\n",
    "            patience       = 1,\n",
    "            device         = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "aabc1814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "torch.save(model.state_dict(), \"FULLTRAINEDALLDATAModelf1-75-learning.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b1d59625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating ['swde_HTMLgraphs/movie/movie/movie-allmovie(2000)'] website type\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.04156546794519418,\n",
       " 0.7552735881680096,\n",
       " 0.7551079869696979,\n",
       " 0.7551907779904338)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_path = \"./FULLTRAINEDALLDATAModelf1-74-learning.pt\"\n",
    "# if os.path.exists(model_path) and load_checkpoint:\n",
    "#     print(\"loading existing model...\")\n",
    "#     model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "\n",
    "eval_edge_model(model, val_loader, focal_loss, device=\"cuda\", use_E_attr=True, use_A_attr=True)\n",
    "#b4 submitting to A100\n",
    "#Experiemnt with the comparison loss\n",
    "#Do self layers myself\n",
    "#\n",
    "#Graphs of also without edges\n",
    "\n",
    "#32 32 layers\n",
    "#Just train everything from the start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
