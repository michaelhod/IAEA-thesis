{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cff77184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from torch.optim import lr_scheduler\n",
    "from scipy import sparse\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import io, tarfile\n",
    "\n",
    "datafile = \"/vol/bitbucket/mjh24/IAEA-thesis/data/swde_HTMLgraphs.tar\"\n",
    "\n",
    "SEED = 16\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562900ca",
   "metadata": {},
   "source": [
    "***BELOW***\n",
    "If data-loading < 5-10 % of total epoch time with num_workers=0, stick with the simple path.\n",
    "Otherwise, parallel loading with share-friendly torch_sparse.SparseTensor\n",
    "almost always pays off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83fd8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────── Tar-reader dataset\n",
    "class TarGraphDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each graph is stored under its own sub-directory *inside* one .tar:\n",
    "\n",
    "        graphs.tar\n",
    "        ├── 0001/X.npz\n",
    "        ├── 0001/E.npz\n",
    "        ├── 0001/edge_index.npy\n",
    "        ├── 0001/labels.npz\n",
    "        ├── 0001/label_index.npy\n",
    "        ├── 0001/label_value.npy\n",
    "        ├── 0002/…\n",
    "        └── …\n",
    "\n",
    "    The tar is opened once; __getitem__ streams the six files for graph *idx*\n",
    "    straight into memory, converts them to native PyTorch tensors and returns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tar_path: str | Path):\n",
    "        self.tar = tarfile.open(tar_path, mode=\"r:*\")      # gzip/none/…\n",
    "        self.index: dict[str, dict[str, tarfile.TarInfo]] = {}\n",
    "\n",
    "        # Build a small lookup table in RAM  {gid: {filename: tarinfo}}\n",
    "        for member in self.tar.getmembers():\n",
    "            if not member.isfile():\n",
    "                continue\n",
    "\n",
    "            p     = Path(member.name)\n",
    "            gid   = str(p.parent)   # '0007'\n",
    "            fname = p.name          # 'X.npz'\n",
    "\n",
    "            # keep only folders that really are 4-digit graph IDs\n",
    "            if gid[-4:].isdigit():\n",
    "                self.index.setdefault(gid, {})[fname] = member\n",
    "\n",
    "\n",
    "        self.gids = sorted(self.index)\n",
    "\n",
    "        # Remove thos with no labels\n",
    "        for gid, files in self.index.items():\n",
    "            if not files.get(\"labels.npz\"):\n",
    "                self.gids.remove(gid)\n",
    "\n",
    "    # ------------- helpers --------------------------------------------------\n",
    "    @staticmethod\n",
    "    def _npz_to_csr(buf: bytes, dtype=torch.float32):\n",
    "        csr = sparse.load_npz(io.BytesIO(buf)).tocsr()\n",
    "        crow = torch.from_numpy(csr.indptr.astype(np.int64))\n",
    "        col  = torch.from_numpy(csr.indices.astype(np.int64))\n",
    "        val  = torch.from_numpy(csr.data).to(dtype)\n",
    "        return torch.sparse_csr_tensor(\n",
    "            crow, col, val, size=csr.shape, dtype=dtype, requires_grad=False\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _npy_to_tensor(buf: bytes, dtype):\n",
    "        arr = np.load(io.BytesIO(buf), allow_pickle=False)\n",
    "        return torch.from_numpy(arr).to(dtype)\n",
    "\n",
    "    # ------------- Dataset API ---------------------------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.gids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gid   = self.gids[idx]\n",
    "        files = self.index[gid]\n",
    "\n",
    "        get = lambda name: self.tar.extractfile(files[name]).read()\n",
    "        \n",
    "        fileinfo = gid\n",
    "\n",
    "        X   = self._npz_to_csr(get(\"X.npz\"),       dtype=torch.float32)\n",
    "        Aef = self._npz_to_csr(get(\"E.npz\"),       dtype=torch.float32)\n",
    "        Lef = self._npz_to_csr(get(\"labels.npz\"),  dtype=torch.float32)\n",
    "\n",
    "        Aei = self._npy_to_tensor(get(\"edge_index.npy\"),  dtype=torch.int64)\n",
    "        Lei = self._npy_to_tensor(get(\"label_index.npy\"), dtype=torch.int64)\n",
    "        y   = self._npy_to_tensor(get(\"label_value.npy\"), dtype=torch.int64)\n",
    "\n",
    "        return fileinfo, X, Aei.t().contiguous(), Aef, Lei.t().contiguous(), Lef, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ad981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_csr(blocks):\n",
    "    \"\"\"\n",
    "    Vertically stack CSR matrices that all share the same n_cols.\n",
    "    Keeps sparsity and returns a single torch.sparse_csr_tensor.\n",
    "    \"\"\"\n",
    "    crow_bufs, col_bufs, val_bufs = [], [], []\n",
    "    nnz_so_far, n_rows, n_cols = 0, 0, blocks[0].size(1)\n",
    "\n",
    "    for k, csr in enumerate(blocks):\n",
    "        crow = csr.crow_indices().clone()          # (n_rows_k + 1,)\n",
    "\n",
    "        # 1) shift by *cumulative* nnz so far\n",
    "        crow += nnz_so_far\n",
    "\n",
    "        # 2) drop the leading 0 for every block after the first\n",
    "        if k > 0:\n",
    "            crow = crow[1:]\n",
    "\n",
    "        crow_bufs.append(crow)\n",
    "        col_bufs.append(csr.col_indices())\n",
    "        val_bufs.append(csr.values())\n",
    "\n",
    "        nnz_so_far += csr.values().numel()\n",
    "        n_rows     += csr.size(0)\n",
    "\n",
    "    crow_cat = torch.cat(crow_bufs)\n",
    "    col_cat  = torch.cat(col_bufs)\n",
    "    val_cat  = torch.cat(val_bufs)\n",
    "\n",
    "    return torch.sparse_csr_tensor(\n",
    "        crow_cat, col_cat, val_cat,\n",
    "        size=(n_rows, n_cols),\n",
    "        dtype=val_cat.dtype,\n",
    "        device=val_cat.device,\n",
    "        requires_grad=False\n",
    "    )\n",
    "\n",
    "\n",
    "def sparse_graph_collate(batch):\n",
    "    # unpack each graph\n",
    "    filenames, xs, aei, aef, lei, lef, ys = zip(*batch)\n",
    "\n",
    "    # node-count prefix sum for shifting\n",
    "    node_offsets = torch.cumsum(\n",
    "        torch.tensor([0] + [x.size(0) for x in xs[:-1]]), 0)\n",
    "\n",
    "    # ----- merge node features (CSR) -----------------------------\n",
    "    X_batch = concat_csr(xs)\n",
    "\n",
    "    # ----- merge structural edges --------------------------------\n",
    "    Aei_shifted = []\n",
    "    for off, ei in zip(node_offsets, aei):\n",
    "        Aei_shifted.append(ei + off)   # shift both rows\n",
    "    Aei_batch = torch.cat(Aei_shifted, dim=1)   # (2 , E_tot)\n",
    "\n",
    "    Aef_batch = concat_csr(aef)\n",
    "\n",
    "    # ----- merge label edges -------------------------------------\n",
    "    Lei_shifted = []\n",
    "    for off, ei in zip(node_offsets, lei):\n",
    "        Lei_shifted.append(ei + off)\n",
    "    Lei_batch = torch.cat(Lei_shifted, dim=1)\n",
    "\n",
    "    Lef_batch = concat_csr(lef)\n",
    "    y_batch   = torch.cat(ys)\n",
    "\n",
    "    return filenames, X_batch, Aei_batch, Aef_batch, Lei_batch, Lef_batch, y_batch\n",
    "\n",
    "def debug_collate(batch):\n",
    "    _, xs, aei, aef, lei, lef, ys = zip(*batch)\n",
    "    print(\"--- one mini-batch ---\")\n",
    "    for i, X in enumerate(xs):\n",
    "        print(f\"graph {i}:  nodes={X.size(0):4d}   \"\n",
    "              f\"struct-edges={aei[i].shape[1]:4d}   \"\n",
    "              f\"label-edges={lei[i].shape[1]:3d}\")\n",
    "    # then call the real collate to keep training code unchanged\n",
    "    return sparse_graph_collate(batch)\n",
    "\n",
    "# ───────────────────────────────────────────────────────── loader utilities\n",
    "def identity_collate(batch):\n",
    "    \"\"\"batch == list of length 1 → return that single sample untouched.\"\"\"\n",
    "    return batch[0]\n",
    "\n",
    "def make_loader(ds, batch_size=1, shuffle=False):\n",
    "    return DataLoader(ds,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      collate_fn=sparse_graph_collate,\n",
    "                      num_workers=0,\n",
    "                      pin_memory=True)    # fast GPU transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec604253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset   = TarGraphDataset(\"../../data/swde_HTMLgraphs.tar\")\n",
    "# loader    = make_loader(dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# next(iter(loader))\n",
    "\n",
    "# count = 0\n",
    "# for fileinfo, X, Aei, Aef, Lei, Lef, y in loader:\n",
    "#     print(fileinfo)\n",
    "#     count +=1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7c7e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a lazy loader for individual files\n",
    "\n",
    "# class LazyGraphDataset(Dataset):\n",
    "#     \"\"\"\n",
    "#     Each graph lives in its own .npz / .pt / whatever on disk.\n",
    "#     __getitem__ loads it just-in-time.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, folderpaths):\n",
    "#         \"\"\"\n",
    "#         meta_csv: a CSV (or list of dicts) with columns:\n",
    "#             path_X, path_A_index, path_A_feat, path_L_index, path_L_feat, path_y\n",
    "#         Only these tiny strings stay in RAM.\n",
    "#         \"\"\"\n",
    "#         self.folderpaths = list(folderpaths)\n",
    "\n",
    "#     def _import_tensor(self, filename: str, dtype: torch.dtype, is_sparse: bool = False):\n",
    "#         \"\"\"\n",
    "#         Load a .npz CSR matrix and return either\n",
    "#         • a torch.sparse_csr_tensor              (if is_sparse=True)\n",
    "#         • a torch.Tensor (dense)                 (otherwise)\n",
    "#         \"\"\"\n",
    "#         csr = sparse.load_npz(filename).tocsr()\n",
    "\n",
    "#         if is_sparse:\n",
    "#             crow = torch.from_numpy(csr.indptr.astype(np.int64))\n",
    "#             col  = torch.from_numpy(csr.indices.astype(np.int64))\n",
    "#             val  = torch.from_numpy(csr.data).to(dtype)\n",
    "#             return torch.sparse_csr_tensor(crow, col, val,size=csr.shape, dtype=dtype, requires_grad=False)\n",
    "#         # — otherwise densify —\n",
    "#         return torch.from_numpy(csr.toarray()).to(dtype)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         folder_path = self.folderpaths[idx]\n",
    "\n",
    "#         X = self._import_tensor((folder_path/\"X.npz\"), torch.float32, is_sparse=False)\n",
    "#         #A = self._import_tensor(folder_path/\"A.npz\", torch.long, True)\n",
    "#         Aef = self._import_tensor((folder_path/\"E.npz\"), torch.float32, is_sparse=True)\n",
    "#         Aei = torch.from_numpy(np.load((folder_path/\"edge_index.npy\")))\n",
    "#         Lef = self._import_tensor((folder_path/\"labels.npz\"), torch.float32, is_sparse=True)\n",
    "#         Lei = torch.from_numpy(np.load((folder_path/\"label_index.npy\")))\n",
    "#         y = torch.from_numpy(np.load((folder_path/\"label_value.npy\")))\n",
    "\n",
    "#         return X, Aei, Aef, Lei, Lef, y\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.folderpaths)\n",
    "\n",
    "# def graph_collate(batch):\n",
    "#     # batch is a list of tuples\n",
    "#     xs, aei, aef, lei, lef, ys = zip(*batch)   # tuples of length B\n",
    "\n",
    "#     return (list(xs),                          # list of sparse X\n",
    "#             list(aei),                         # list of edge_index\n",
    "#             list(aef),                         # list of sparse A_edge_feat\n",
    "#             list(lei),\n",
    "#             list(lef),\n",
    "#             list(ys))                          # dense y can still be list/stack\n",
    "\n",
    "# def make_loader(dataset, batch_size=1, shuffle=False):\n",
    "#     return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=graph_collate, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f02934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def walk_limited(root: Path, max_depth: int, pat: str):\n",
    "#     root_depth = len(root.parts)\n",
    "#     for dirpath, dirnames, _ in os.walk(root):\n",
    "#         depth = len(Path(dirpath).parts) - root_depth\n",
    "#         if depth > max_depth:\n",
    "#             # prune traversal\n",
    "#             dirnames[:] = []\n",
    "#             continue\n",
    "#         for d in dirnames:\n",
    "#             p = Path(dirpath, d)\n",
    "#             if p.match(pat):\n",
    "#                 yield p\n",
    "\n",
    "# src = Path(\"/vol/bitbucket/mjh24/IAEA-thesis/data/swde_HTMLgraphs/movie/movie\")\n",
    "# batch_dirs = list(walk_limited(src, max_depth=2, pat='[0-9][0-9][0-9][0-9]'))\n",
    "# print(src.exists())\n",
    "# batchFiles = list(src.rglob(\"[0-9][0-9][0-9][0-9]\"))\n",
    "# print(len(batchFiles))\n",
    "# dataset = LazyGraphDataset(batchFiles)\n",
    "# dataloader = make_loader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d224978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Xs, Aeis, Aefs, Leis, Lefs, ys in dataloader:\n",
    "#     print(Xs[0].shape, Aeis[0].shape, Aefs[0].shape, Leis[0].shape, Lefs[0].shape, ys[0].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e379c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to normalise the A matrix\n",
    "def symmetric_normalize(A_tilde):\n",
    "    \"\"\"\n",
    "    Performs symmetric normalization of A_tilde (Adj. matrix with self loops):\n",
    "      A_norm = D^{-1/2} * A_tilde * D^{-1/2}\n",
    "    Where D_{ii} = sum of row i in A_tilde.\n",
    "\n",
    "    A_tilde (N, N): Adj. matrix with self loops\n",
    "    Returns:\n",
    "      A_norm : (N, N)\n",
    "    \"\"\"\n",
    "\n",
    "    eps = 1e-5\n",
    "    d = A_tilde.sum(dim=1) + eps\n",
    "    D_inv = torch.diag(torch.pow(d, -0.5))\n",
    "    return (D_inv @ A_tilde @ D_inv).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "749c7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To advance the model, use the methods in https://arxiv.org/pdf/2311.02921\n",
    "\n",
    "class GraphAttentionNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    HTML‑graph model\n",
    "\n",
    "        X  ─╮\n",
    "            │  GAT( 96 → 64 )\n",
    "            │  ReLU\n",
    "            │  GAT( 64 → 32 )\n",
    "            │  ReLU\n",
    "            └─ Edge‑feature constructor\n",
    "                      [h_i ‖ h_j ‖ φ(e_ij)] ─► MLP(69 → 1)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_dim          : node‑feature size   (= 96)\n",
    "    edge_in_dim     : raw edge‑feature size (= 197)\n",
    "    edge_emb_dim    : Edge-feature MLP output dims\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_dim: int        = 96,\n",
    "                 edge_in_dim: int   = 197,\n",
    "                 edge_emb_dim: int  = 8,\n",
    "                 hidden1: int       = 64,\n",
    "                 hidden2: int       = 32,\n",
    "                 heads:  int        = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        # ── Node-level encoder (edge-aware) ────────────────────────────\n",
    "        self.gat1 = GATv2Conv(in_dim,\n",
    "                              hidden1,\n",
    "                              heads=heads,\n",
    "                              concat=True,\n",
    "                              edge_dim=edge_emb_dim,\n",
    "                              fill_value=0.0)\n",
    "\n",
    "        self.gat2 = GATv2Conv(hidden1 * heads,\n",
    "                              hidden2,\n",
    "                              heads=1,\n",
    "                              concat=True,\n",
    "                              edge_dim=edge_emb_dim,\n",
    "                              fill_value=0.0)\n",
    "\n",
    "        # ── Edge feature projector ────────────── (It is not an explicit linear layer as it works on a sparse matrix)\n",
    "        self.W_edge = nn.Parameter(torch.empty(edge_in_dim, edge_emb_dim))\n",
    "        nn.init.xavier_uniform_(self.W_edge)\n",
    "\n",
    "        # ── Edge-level MLP decoder (unchanged) ────────────────────────\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden2 * 2 + edge_emb_dim, hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden2, 1)\n",
    "        )\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_dense: torch.Tensor,        # (N_nodes, 96)          sparse\n",
    "        A_edge_index: torch.Tensor,   # (2, nnz_A)             COO  (from A)\n",
    "        A_edge_attr: torch.Tensor,    # (nnz_A, 197)           dense / sparse.mm\n",
    "        E_edge_index: torch.Tensor,   # (2, N_E)               candidates\n",
    "        E_edge_attr: torch.Tensor     # (N_E, 197)             sparse features\n",
    "    ):\n",
    "        # 1) node features\n",
    "        #x = x_sparse.to_dense()\n",
    "        A_edge_emb = torch.sparse.mm(A_edge_attr, self.W_edge)     # (nnz_A , 8)\n",
    "        \n",
    "        # 2) edge-aware GATv2 layers\n",
    "        h = F.relu(self.gat1(x_dense, A_edge_index, A_edge_emb))\n",
    "        h = F.relu(self.gat2(h, A_edge_index, A_edge_emb))   # (N_nodes , 32)\n",
    "        \n",
    "        # 3) candidate-edge projection  φ(E) = E @ W_edge\n",
    "        E_edge_emb = torch.sparse.mm(E_edge_attr, self.W_edge)     # (N_E , 8)\n",
    "        \n",
    "        # 4) gather node embeddings and classify\n",
    "        src, dst = E_edge_index\n",
    "        z = torch.cat([h[src], h[dst], E_edge_emb], dim=1)      # (N_E , 72)\n",
    "        return self.edge_mlp(z).squeeze(-1)                   # (N_E ,) returns the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96e35002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits as BCEwLogits\n",
    "\n",
    "CLIP_NORM = 1.0           # gradient clipping\n",
    "\n",
    "\n",
    "# ---------- one epoch --------------------------------------------------------\n",
    "def train_epoch(model, loader, optimizer,\n",
    "                criterion=BCEwLogits, device=\"cpu\"):\n",
    "\n",
    "    model.train()\n",
    "    running_loss, running_edges = 0.0, 0\n",
    "    count = 0\n",
    "    l = len(loader)\n",
    "\n",
    "    for _, X, Aei, Aef, Lei, Lef, y in loader:\n",
    "        count += 1\n",
    "        X, Aei, Aef = X.to(device), Aei.to(device), Aef.to(device)\n",
    "        Lei, Lef, y = Lei.to(device), Lef.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(X, Aei, Aef, Lei, Lef)          # (N_label,)\n",
    "        loss   = criterion(logits, y.float())\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss  += loss.item() * y.numel()\n",
    "        running_edges += y.numel()\n",
    "\n",
    "        if count % 200 == 0:\n",
    "            print(f\"file {count}/{l}\"\n",
    "                    f\"loss={loss:.4f}\")\n",
    "\n",
    "    return running_loss / running_edges\n",
    "\n",
    "\n",
    "# ---------- evaluation -------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def eval_edge_model(model, loader, device=\"cpu\", thr=0.5):\n",
    "    model.eval()\n",
    "    TP = FP = FN = 0\n",
    "\n",
    "    for _, X, Aei, Aef, Lei, Lef, y in loader:\n",
    "        X, Aei, Aef = X.to(device), Aei.to(device), Aef.to(device)\n",
    "        Lei, Lef, y = Lei.to(device), Lef.to(device), y.to(device)\n",
    "\n",
    "        logits = model(X, Aei, Aef, Lei, Lef)\n",
    "        probs  = torch.sigmoid(logits)\n",
    "\n",
    "        pred = (probs >= thr).long()\n",
    "        TP  += ((pred == 1) & (y == 1)).sum().item()\n",
    "        FP  += ((pred == 1) & (y == 0)).sum().item()\n",
    "        FN  += ((pred == 0) & (y == 1)).sum().item()\n",
    "\n",
    "    prec = TP / (TP + FP + 1e-9)\n",
    "    rec  = TP / (TP + FN + 1e-9)\n",
    "    f1   = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "    return prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67146255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                num_epochs     = 100,\n",
    "                lr             = 1e-3,\n",
    "                validate_every = 10,\n",
    "                patience       = 10,\n",
    "                device         = \"cpu\"):\n",
    "\n",
    "    print(\"Woo lets go\")\n",
    "    model.to(device)\n",
    "    \n",
    "    opt   = optim.AdamW(model.parameters(), lr=lr)\n",
    "    sched = lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\",\n",
    "                                          patience=patience, factor=0.5)\n",
    "\n",
    "    best_f1, best_state, hist = 0.0, None, []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        \n",
    "        loss = train_epoch(model, train_loader, opt, device=device)\n",
    "        hist.append(loss)\n",
    "\n",
    "        if epoch % validate_every == 0 or epoch == num_epochs:\n",
    "            p, r, f1 = eval_edge_model(model, val_loader, device=device)\n",
    "            sched.step(f1)\n",
    "\n",
    "            lr_now = opt.param_groups[0][\"lr\"]\n",
    "            print(f\"Epoch {epoch:03d}/{num_epochs} \"\n",
    "                  f\"loss={loss:.4f}  P={p:.3f} R={r:.3f} F1={f1:.3f}  lr={lr_now:.2e}\")\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_state = f1, copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if lr_now < 1e-7:\n",
    "                print(\"Stop: LR < 1e-7\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return hist, best_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbfe9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Woo lets go\n",
      "file 200/1375loss=0.5402\n",
      "file 400/1375loss=0.5252\n",
      "file 600/1375loss=0.5691\n",
      "file 800/1375loss=0.3724\n",
      "file 1000/1375loss=0.3579\n",
      "file 1200/1375loss=0.4467\n",
      "Epoch 001/10 loss=0.4842  P=0.703 R=0.250 F1=0.369  lr=1.00e-04\n",
      "file 200/1375loss=0.3635\n",
      "file 400/1375loss=0.4133\n",
      "file 600/1375loss=0.4510\n",
      "file 800/1375loss=0.4245\n",
      "file 1000/1375loss=0.3295\n",
      "file 1200/1375loss=0.5054\n",
      "Epoch 002/10 loss=0.3620  P=0.794 R=0.323 F1=0.460  lr=1.00e-04\n",
      "file 200/1375loss=0.4117\n",
      "file 400/1375loss=0.2914\n",
      "file 600/1375loss=0.2454\n",
      "file 800/1375loss=0.2828\n",
      "file 1000/1375loss=0.2329\n",
      "file 1200/1375loss=0.2241\n",
      "Epoch 003/10 loss=0.2883  P=0.830 R=0.386 F1=0.527  lr=1.00e-04\n",
      "file 200/1375loss=0.2601\n",
      "file 400/1375loss=0.2299\n",
      "file 600/1375loss=0.2550\n",
      "file 800/1375loss=0.1909\n",
      "file 1000/1375loss=0.2018\n",
      "file 1200/1375loss=0.2456\n",
      "Epoch 004/10 loss=0.2420  P=0.849 R=0.383 F1=0.528  lr=1.00e-04\n",
      "file 200/1375loss=0.2360\n",
      "file 400/1375loss=0.1777\n",
      "file 600/1375loss=0.1745\n",
      "file 800/1375loss=0.1765\n",
      "file 1000/1375loss=0.1390\n",
      "file 1200/1375loss=0.2452\n",
      "Epoch 005/10 loss=0.2118  P=0.854 R=0.416 F1=0.560  lr=1.00e-04\n",
      "file 200/1375loss=0.1606\n",
      "file 400/1375loss=0.1750\n",
      "file 600/1375loss=0.2177\n",
      "file 800/1375loss=0.1830\n",
      "file 1000/1375loss=0.2308\n",
      "file 1200/1375loss=0.1579\n",
      "Epoch 006/10 loss=0.1922  P=0.860 R=0.351 F1=0.498  lr=1.00e-04\n",
      "file 200/1375loss=0.1526\n",
      "file 400/1375loss=0.1596\n",
      "file 600/1375loss=0.2034\n",
      "file 800/1375loss=0.1534\n",
      "file 1000/1375loss=0.2006\n",
      "file 1200/1375loss=0.1215\n",
      "Epoch 007/10 loss=0.1779  P=0.865 R=0.376 F1=0.524  lr=1.00e-04\n",
      "file 200/1375loss=0.1732\n",
      "file 400/1375loss=0.1738\n",
      "file 600/1375loss=0.1485\n",
      "file 800/1375loss=0.1619\n",
      "file 1000/1375loss=0.1890\n",
      "file 1200/1375loss=0.1545\n",
      "Epoch 008/10 loss=0.1662  P=0.865 R=0.363 F1=0.511  lr=1.00e-04\n",
      "file 200/1375loss=0.1338\n",
      "file 400/1375loss=0.1634\n",
      "file 600/1375loss=0.1302\n",
      "file 800/1375loss=0.1663\n",
      "file 1000/1375loss=0.1495\n",
      "file 1200/1375loss=0.1419\n",
      "Epoch 009/10 loss=0.1562  P=0.871 R=0.339 F1=0.488  lr=1.00e-04\n",
      "file 200/1375loss=0.1486\n",
      "file 400/1375loss=0.1333\n",
      "file 600/1375loss=0.1497\n",
      "file 800/1375loss=0.1498\n",
      "file 1000/1375loss=0.1896\n",
      "file 1200/1375loss=0.1407\n",
      "Epoch 010/10 loss=0.1491  P=0.852 R=0.384 F1=0.530  lr=1.00e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.48421053048208185,\n",
       "  0.36200163457935514,\n",
       "  0.28829705891224583,\n",
       "  0.24196659862162986,\n",
       "  0.21178811744948214,\n",
       "  0.1922064089796834,\n",
       "  0.17787765001225914,\n",
       "  0.16622202366900113,\n",
       "  0.15620665470440423,\n",
       "  0.14908609250555296],\n",
       " OrderedDict([('W_edge',\n",
       "               tensor([[ 0.6175,  0.1388,  0.0583,  ..., -0.0453,  0.0890, -0.3845],\n",
       "                       [ 0.0200,  0.0932, -0.1590,  ..., -0.0156, -0.1283, -0.1527],\n",
       "                       [ 0.0203, -0.1427, -0.1556,  ..., -0.0420,  0.1438,  0.0430],\n",
       "                       ...,\n",
       "                       [ 0.1891,  0.2192, -0.2120,  ..., -0.0027, -0.0603,  0.2145],\n",
       "                       [ 0.0499, -0.0335, -0.0106,  ..., -0.2287, -0.0473,  0.0368],\n",
       "                       [ 0.1608, -0.0024,  0.2297,  ...,  0.0974,  0.0861,  0.0660]],\n",
       "                      device='cuda:0')),\n",
       "              ('gat1.att',\n",
       "               tensor([[[ 0.2698, -0.1355,  0.3188, -0.3411,  0.3084,  0.1723,  0.0918,\n",
       "                          0.0309,  0.1811, -0.3325, -0.1853, -0.1008, -0.2120,  0.2657,\n",
       "                         -0.1911, -0.1316, -0.2158, -0.0870,  0.2393,  0.3568, -0.1867,\n",
       "                          0.2923,  0.3749,  0.0536,  0.2745, -0.0771, -0.3222, -0.0103,\n",
       "                         -0.2775, -0.1378, -0.1046, -0.2121, -0.1257, -0.2801,  0.3033,\n",
       "                         -0.1742,  0.1061, -0.3337,  0.1991, -0.1925,  0.0498, -0.4236,\n",
       "                          0.1493,  0.0762, -0.2744, -0.2542,  0.2355,  0.2840,  0.1656,\n",
       "                         -0.0395, -0.1154,  0.1399,  0.2851,  0.2030,  0.2199,  0.2518,\n",
       "                         -0.1152,  0.1270, -0.2740, -0.0568, -0.0756,  0.3840,  0.1674,\n",
       "                         -0.1748]]], device='cuda:0')),\n",
       "              ('gat1.bias',\n",
       "               tensor([ 0.1701,  0.2179,  0.1101,  0.1322,  0.0713,  0.1138, -0.0308,  0.1650,\n",
       "                        0.1137, -0.0261,  0.1346,  0.0739,  0.0506,  0.1216,  0.0555,  0.0495,\n",
       "                        0.1291,  0.0791, -0.0078, -0.0351,  0.0888,  0.0465,  0.1795,  0.2501,\n",
       "                        0.1132, -0.0266,  0.0557,  0.1536,  0.0640,  0.1156,  0.1765,  0.0674,\n",
       "                        0.0292,  0.0015,  0.1297,  0.0886,  0.2271,  0.0668,  0.0743,  0.2066,\n",
       "                        0.1939, -0.1307,  0.0638,  0.0464,  0.2662,  0.1961,  0.0768,  0.0424,\n",
       "                        0.0525,  0.0336,  0.0519,  0.0947,  0.1571, -0.0341,  0.1078,  0.1365,\n",
       "                        0.1995,  0.0754,  0.0694,  0.1799, -0.0072,  0.0797,  0.0619,  0.1088],\n",
       "                      device='cuda:0')),\n",
       "              ('gat1.lin_l.weight',\n",
       "               tensor([[ 0.4811, -0.1477, -0.0083,  ...,  0.1492, -0.1660,  0.0395],\n",
       "                       [ 0.0125, -0.1206, -0.0919,  ..., -0.1696, -0.0903,  0.1736],\n",
       "                       [-0.1503, -0.1437, -0.1392,  ..., -0.0551,  0.1230,  0.0103],\n",
       "                       ...,\n",
       "                       [-0.0186,  0.1492,  0.0278,  ...,  0.0476, -0.1215, -0.1492],\n",
       "                       [ 0.2241, -0.1642, -0.0775,  ..., -0.0296, -0.0889,  0.1041],\n",
       "                       [-0.0785, -0.1476,  0.0956,  ..., -0.0394, -0.0196, -0.0006]],\n",
       "                      device='cuda:0')),\n",
       "              ('gat1.lin_l.bias',\n",
       "               tensor([ 0.1799,  0.1301,  0.1959,  0.1203, -0.2257,  0.0616, -0.0065,  0.1463,\n",
       "                        0.1758, -0.1109,  0.1553,  0.0216, -0.0377,  0.1203,  0.0424,  0.1358,\n",
       "                        0.1629,  0.0205,  0.0436,  0.1820,  0.0074,  0.0363,  0.1369,  0.2272,\n",
       "                        0.0564, -0.1158,  0.1580,  0.1983,  0.0703,  0.2021,  0.1030,  0.0863,\n",
       "                        0.0918,  0.0053,  0.0753,  0.0349,  0.1787,  0.1357, -0.0169,  0.3039,\n",
       "                        0.1973, -0.1535,  0.1103,  0.0292,  0.2196,  0.2860,  0.0315,  0.1221,\n",
       "                        0.1262,  0.0538,  0.0905, -0.0255,  0.2358, -0.0567,  0.0519,  0.0943,\n",
       "                        0.2040,  0.1209,  0.1012,  0.1261,  0.0908,  0.1408,  0.0043,  0.1698],\n",
       "                      device='cuda:0')),\n",
       "              ('gat1.lin_r.weight',\n",
       "               tensor([[-1.5362e-01, -1.4184e-01, -4.2402e-04,  ...,  1.2418e-01,\n",
       "                        -5.5275e-03,  1.5607e-01],\n",
       "                       [-1.3963e-01,  3.3911e-02, -6.7133e-02,  ...,  1.1243e-01,\n",
       "                         1.2212e-01,  1.8133e-01],\n",
       "                       [-5.1683e-02,  6.3207e-02,  9.1650e-02,  ...,  1.6797e-01,\n",
       "                         1.8531e-01,  8.0831e-02],\n",
       "                       ...,\n",
       "                       [-5.0117e-02, -4.2755e-03, -2.3894e-02,  ...,  6.8208e-02,\n",
       "                         1.2413e-01,  3.3761e-01],\n",
       "                       [-4.6484e-01,  2.0056e-02,  1.5877e-01,  ...,  4.8724e-03,\n",
       "                         4.8068e-02, -3.3590e-01],\n",
       "                       [ 4.0978e-01,  4.6954e-02,  7.3573e-02,  ..., -8.6504e-02,\n",
       "                         1.1565e-01, -1.9069e-01]], device='cuda:0')),\n",
       "              ('gat1.lin_r.bias',\n",
       "               tensor([ 0.1356, -0.0424,  0.1686,  0.1987, -0.1897, -0.1265, -0.1495,  0.1521,\n",
       "                       -0.1124,  0.1436,  0.0733, -0.1632, -0.3266,  0.0077,  0.0336, -0.0601,\n",
       "                        0.0018,  0.0105, -0.0781,  0.2326,  0.2678, -0.2244,  0.0615,  0.0996,\n",
       "                       -0.1591, -0.1079,  0.1653, -0.0634,  0.0534, -0.0627,  0.1694,  0.2150,\n",
       "                       -0.0324,  0.0489,  0.0230,  0.1047, -0.2097,  0.1923,  0.2170, -0.0789,\n",
       "                        0.2933,  0.2848,  0.1391,  0.0799,  0.0501, -0.1785, -0.0345,  0.0366,\n",
       "                       -0.3272,  0.1143, -0.2620, -0.1043,  0.2084,  0.1433, -0.2264, -0.0644,\n",
       "                        0.1419, -0.2822, -0.1069,  0.1497,  0.0771,  0.1844, -0.4128, -0.2070],\n",
       "                      device='cuda:0')),\n",
       "              ('gat1.lin_edge.weight',\n",
       "               tensor([[-3.5873e-02,  9.7003e-02,  1.6194e-01,  1.4641e-01, -1.4943e-01,\n",
       "                         2.3427e-01, -1.8371e-01, -1.2208e-01],\n",
       "                       [ 9.6857e-03,  1.3772e-02,  2.7227e-01, -6.7839e-02, -2.3359e-01,\n",
       "                         1.8698e-01,  1.4492e-01, -2.5462e-01],\n",
       "                       [-2.1827e-02,  1.5312e-01, -5.7889e-02,  1.2862e-01,  1.8580e-01,\n",
       "                         2.9928e-01,  3.4859e-01,  1.8642e-01],\n",
       "                       [-1.2230e-01, -1.5151e-01, -1.3800e-02, -1.5269e-01,  3.6064e-02,\n",
       "                        -1.4868e-01,  1.1684e-01, -2.7000e-01],\n",
       "                       [-3.2541e-01,  2.5916e-01, -2.9825e-01,  2.7307e-01,  1.0668e-01,\n",
       "                        -1.6729e-01, -2.5752e-01,  1.1082e-02],\n",
       "                       [ 1.1548e-01, -2.1265e-01,  1.1708e-02,  3.0128e-01, -8.3485e-02,\n",
       "                         2.2958e-01,  1.1676e-01, -1.4929e-01],\n",
       "                       [-1.8129e-02, -7.7188e-02, -2.5486e-01, -1.5809e-01,  1.2479e-01,\n",
       "                        -1.5040e-01,  2.8484e-01, -2.1331e-02],\n",
       "                       [ 1.8392e-01, -2.5781e-01,  2.3209e-01,  4.1708e-02, -1.9806e-01,\n",
       "                         9.7171e-02,  1.2876e-01, -8.2174e-02],\n",
       "                       [ 2.0498e-01,  1.8806e-01,  2.0866e-01, -2.8912e-01,  1.2526e-01,\n",
       "                        -8.1084e-02, -3.0695e-01,  2.3451e-01],\n",
       "                       [ 1.8974e-01,  2.7091e-01, -1.4977e-01,  4.4890e-02, -2.7656e-01,\n",
       "                        -1.4527e-01, -2.5983e-01, -1.5804e-01],\n",
       "                       [-8.7556e-03,  2.1569e-01,  2.8762e-01, -1.0041e-01, -2.2412e-01,\n",
       "                         9.4529e-02, -1.1506e-02, -3.2785e-01],\n",
       "                       [-8.3983e-02, -9.8444e-04, -6.3613e-02, -1.0958e-01,  4.8751e-02,\n",
       "                         1.9272e-01, -2.1045e-02, -2.9846e-01],\n",
       "                       [ 5.5540e-02, -2.0628e-01, -1.1092e-01,  5.3194e-02, -1.9475e-01,\n",
       "                        -6.0822e-02,  1.4914e-01,  2.8112e-04],\n",
       "                       [ 1.9167e-02,  2.1509e-01, -1.2551e-01, -2.0105e-01, -7.4779e-02,\n",
       "                        -6.8982e-02, -2.7490e-01,  3.1562e-02],\n",
       "                       [ 1.7237e-01,  2.4472e-01, -2.5427e-01,  1.7321e-01, -2.8161e-01,\n",
       "                         3.4796e-02, -2.9615e-01, -8.6237e-02],\n",
       "                       [ 3.7906e-01, -1.8637e-01,  4.7280e-02, -9.9252e-02, -1.0257e-01,\n",
       "                         7.6631e-02, -1.5295e-01,  3.8975e-03],\n",
       "                       [ 2.9204e-01,  6.0527e-02, -1.2508e-01,  1.4308e-01,  1.5745e-01,\n",
       "                        -1.2841e-01, -2.1396e-01,  2.1358e-01],\n",
       "                       [ 9.7868e-02, -2.8580e-01,  2.3182e-01,  1.4519e-01, -2.3874e-01,\n",
       "                         3.8563e-02, -1.3599e-01, -1.5558e-01],\n",
       "                       [ 2.5601e-01, -1.7127e-01,  2.9886e-01, -7.8996e-02, -7.9027e-02,\n",
       "                         3.0181e-01,  4.8670e-02,  1.4012e-01],\n",
       "                       [-1.9917e-01,  1.2505e-01,  2.9425e-02, -1.0541e-01, -1.9290e-01,\n",
       "                        -1.5262e-02,  5.3846e-02,  2.3967e-01],\n",
       "                       [-2.3013e-01,  1.8690e-01,  1.4295e-01, -2.7241e-01,  3.3026e-02,\n",
       "                        -1.3566e-01, -2.7583e-01, -1.7708e-01],\n",
       "                       [-1.4547e-01,  1.6207e-01,  1.1857e-02, -1.9452e-01, -1.7475e-01,\n",
       "                        -2.9620e-01,  2.2216e-01,  1.0017e-01],\n",
       "                       [ 2.9244e-02, -1.7179e-01, -2.8463e-01,  1.2958e-01, -2.0034e-01,\n",
       "                         4.7560e-02, -7.3670e-02, -2.1316e-01],\n",
       "                       [ 1.8510e-01, -1.2052e-01,  5.7082e-02,  2.0851e-01,  1.7954e-01,\n",
       "                        -2.7568e-01, -2.3062e-01, -1.5604e-01],\n",
       "                       [ 1.6670e-01, -6.8846e-02, -1.8723e-01, -1.5012e-01, -5.6246e-02,\n",
       "                        -2.6858e-01, -1.4139e-03,  1.9501e-01],\n",
       "                       [ 8.1399e-02,  3.1064e-02,  1.4398e-01, -2.9208e-01,  7.7659e-03,\n",
       "                         9.5723e-02,  1.1382e-01, -2.5640e-02],\n",
       "                       [ 7.2572e-02,  1.5686e-01, -1.6682e-01, -2.7282e-02,  1.6664e-01,\n",
       "                         7.1483e-02, -1.3382e-01,  3.8975e-02],\n",
       "                       [-1.5657e-01,  1.6513e-01,  1.0523e-01, -2.4186e-01,  3.1535e-02,\n",
       "                        -5.2868e-02, -1.5515e-01, -9.2012e-02],\n",
       "                       [ 4.6940e-02, -1.0303e-01, -1.5416e-01,  3.2026e-01, -2.8465e-01,\n",
       "                         1.2153e-01, -1.9831e-01,  8.7338e-02],\n",
       "                       [ 1.9061e-01, -4.9468e-02,  2.1285e-01,  2.5536e-02,  2.6739e-02,\n",
       "                        -1.2724e-01, -1.7725e-01,  1.7415e-01],\n",
       "                       [-5.0943e-02, -2.1343e-01, -1.0313e-01, -1.8508e-01,  1.4476e-02,\n",
       "                         1.2409e-01,  6.9248e-02,  2.6251e-01],\n",
       "                       [-1.7320e-01, -2.1614e-01, -1.5955e-02,  1.7406e-01, -1.8568e-01,\n",
       "                        -2.7002e-02,  2.3940e-01, -4.3779e-02],\n",
       "                       [-2.2581e-01, -1.1012e-01,  3.3051e-02,  1.8423e-01, -1.3911e-01,\n",
       "                         1.2750e-01,  6.3586e-02, -2.3027e-01],\n",
       "                       [-2.6500e-02,  1.4043e-01, -9.1698e-02, -7.0077e-02, -2.0834e-02,\n",
       "                         9.9043e-03, -2.5559e-01,  1.9729e-01],\n",
       "                       [-3.9821e-02, -2.4624e-01, -2.8397e-01, -1.2790e-01,  5.6215e-02,\n",
       "                        -1.7623e-03,  1.6572e-01,  2.0171e-01],\n",
       "                       [ 1.1615e-01, -8.9622e-02,  6.0593e-02, -1.5466e-01, -1.2749e-01,\n",
       "                        -3.4440e-01,  1.8900e-01, -1.3159e-01],\n",
       "                       [-1.8101e-01,  1.6730e-01,  2.6973e-01,  3.1275e-01, -1.0839e-01,\n",
       "                        -2.4638e-01, -1.8091e-01, -4.0469e-02],\n",
       "                       [ 4.5404e-02,  2.6490e-01,  2.0240e-02, -2.2953e-01,  2.4479e-02,\n",
       "                         9.4623e-03, -2.9388e-01,  1.0006e-01],\n",
       "                       [-8.3847e-02,  6.6495e-02,  2.4877e-01, -1.8784e-01,  1.6592e-03,\n",
       "                         2.9154e-01, -4.2421e-02, -1.2623e-01],\n",
       "                       [-1.5859e-01,  1.9066e-01, -2.0946e-01,  1.1345e-01, -2.6574e-01,\n",
       "                         2.4546e-01, -1.5927e-01, -6.5628e-03],\n",
       "                       [-1.0307e-01,  9.4392e-02, -9.8203e-02, -1.4186e-01,  9.4184e-02,\n",
       "                         8.3582e-02,  2.7719e-01,  1.2575e-01],\n",
       "                       [ 1.4028e-01, -2.1616e-01,  1.1785e-01, -2.0426e-02, -8.9414e-02,\n",
       "                        -2.2672e-01, -2.5052e-01, -5.9559e-02],\n",
       "                       [-1.9132e-01,  8.5586e-02,  9.8152e-02, -2.0828e-02, -1.5663e-01,\n",
       "                        -2.2990e-01, -1.8524e-01,  9.9336e-02],\n",
       "                       [-3.5393e-02, -2.9460e-01, -7.6262e-03,  1.0914e-01,  7.1758e-02,\n",
       "                         5.6929e-02,  2.0479e-01, -2.4453e-01],\n",
       "                       [ 1.6480e-01, -1.4174e-01,  2.1652e-01,  2.3814e-01,  9.5906e-02,\n",
       "                         3.8554e-02,  1.8130e-01,  1.3812e-01],\n",
       "                       [ 1.2674e-01, -2.8671e-01, -2.5219e-02,  5.4590e-02,  1.2183e-01,\n",
       "                        -9.2275e-02,  4.5208e-02, -2.4101e-01],\n",
       "                       [ 4.4675e-02,  2.5314e-01, -4.6014e-03, -3.6893e-02,  5.7398e-02,\n",
       "                         1.8272e-01, -7.4126e-02,  3.2716e-02],\n",
       "                       [ 1.6577e-01, -2.1672e-01, -1.6198e-01, -6.0468e-02, -1.8894e-01,\n",
       "                        -6.9163e-02,  2.7525e-02, -1.7158e-01],\n",
       "                       [-1.4665e-02,  1.9055e-01, -2.7194e-01, -8.3079e-02, -1.3549e-01,\n",
       "                        -2.4569e-01, -1.2201e-01,  6.9062e-02],\n",
       "                       [-4.8655e-02, -1.2270e-01,  1.4166e-01, -1.2087e-01,  2.5705e-01,\n",
       "                        -8.6724e-02,  7.9581e-02, -2.0388e-02],\n",
       "                       [-2.4908e-01,  1.6893e-01,  8.1382e-02, -2.8063e-01,  2.8818e-01,\n",
       "                         5.9992e-02,  1.2353e-01, -3.0871e-01],\n",
       "                       [ 4.9871e-02, -7.2652e-02,  2.8561e-01, -3.9208e-02, -1.9170e-01,\n",
       "                        -1.8270e-01, -2.0632e-01,  1.1800e-01],\n",
       "                       [-2.1667e-01,  2.5454e-01,  1.3820e-01, -6.8436e-02, -3.5150e-02,\n",
       "                         1.3928e-01,  2.9704e-01, -6.1405e-02],\n",
       "                       [-2.1234e-01, -1.0800e-01,  1.4075e-01, -8.4224e-02, -1.4470e-01,\n",
       "                        -2.9299e-01,  3.4010e-02, -1.4895e-01],\n",
       "                       [-1.1194e-01,  2.6266e-01,  1.6092e-01,  3.8601e-03,  2.8195e-01,\n",
       "                         1.7388e-01,  2.9169e-01,  1.2557e-01],\n",
       "                       [-1.5301e-01, -2.3469e-01,  7.0271e-02,  2.0013e-01, -2.0415e-01,\n",
       "                        -1.1424e-02,  2.8869e-01,  7.6210e-02],\n",
       "                       [ 1.2126e-01,  2.4178e-01, -2.2869e-01, -2.9472e-01,  1.5281e-01,\n",
       "                        -8.9751e-02,  2.7270e-01,  2.0112e-01],\n",
       "                       [ 1.3075e-01,  1.6864e-01, -3.0936e-01,  1.3670e-01,  9.9191e-02,\n",
       "                         6.3128e-02, -1.9395e-01, -1.8332e-01],\n",
       "                       [ 4.1845e-02,  2.9201e-01,  8.7116e-02,  6.4944e-03,  1.5735e-01,\n",
       "                         5.6205e-03,  9.0421e-02,  1.3413e-01],\n",
       "                       [ 4.7723e-02, -1.8724e-01,  2.2808e-01, -8.6402e-02,  8.9994e-02,\n",
       "                        -7.8634e-02,  2.2047e-01,  9.9458e-02],\n",
       "                       [-3.1394e-01, -9.1544e-02,  2.4272e-01,  1.9231e-01,  5.6174e-02,\n",
       "                         3.6923e-03,  2.6425e-01, -3.3570e-01],\n",
       "                       [-6.1229e-02, -1.6454e-01,  2.6749e-03,  1.3313e-01,  1.6637e-02,\n",
       "                        -2.6624e-01,  3.6127e-03, -2.8640e-02],\n",
       "                       [-2.6831e-01, -8.7904e-02,  8.8267e-03,  8.4432e-03,  3.2166e-02,\n",
       "                        -3.0501e-01, -1.1590e-01,  1.5457e-01],\n",
       "                       [ 2.6981e-01,  4.3383e-02,  6.0957e-02, -7.0342e-03,  1.3583e-01,\n",
       "                        -9.4948e-02, -3.0273e-01,  2.6266e-02]], device='cuda:0')),\n",
       "              ('gat2.att',\n",
       "               tensor([[[-0.4017,  0.2453,  0.3871,  0.4411, -0.0197, -0.3754, -0.3649,\n",
       "                         -0.2069, -0.3980,  0.2746,  0.1556, -0.2779, -0.2116, -0.3776,\n",
       "                          0.3703,  0.4691, -0.0820, -0.1706,  0.1376, -0.3494,  0.1724,\n",
       "                         -0.0901,  0.4291, -0.1485, -0.3635, -0.3369,  0.2314,  0.1170,\n",
       "                          0.1712, -0.2874, -0.2789,  0.1835]]], device='cuda:0')),\n",
       "              ('gat2.bias',\n",
       "               tensor([ 0.1694,  0.2179,  0.0306,  0.2365,  0.0817,  0.1827,  0.0049,  0.0374,\n",
       "                        0.2184,  0.1437,  0.0946,  0.0651,  0.0470,  0.0365,  0.0852,  0.0274,\n",
       "                        0.0094,  0.0961,  0.0817,  0.0712, -0.0949,  0.1013,  0.0546,  0.1115,\n",
       "                        0.0536,  0.0817, -0.0132,  0.0658,  0.0595,  0.1039,  0.0003,  0.0443],\n",
       "                      device='cuda:0')),\n",
       "              ('gat2.lin_l.weight',\n",
       "               tensor([[ 0.0687, -0.1738, -0.2409,  ...,  0.0977, -0.1062,  0.1798],\n",
       "                       [ 0.1711,  0.1286,  0.4169,  ...,  0.0315,  0.3808,  0.5439],\n",
       "                       [-0.2088,  0.0365, -0.2717,  ...,  0.5181, -0.0611,  0.0585],\n",
       "                       ...,\n",
       "                       [-0.0897,  0.1727,  0.0708,  ...,  0.0600,  0.0639,  0.4823],\n",
       "                       [ 0.3403,  0.1527, -0.3672,  ...,  0.5200,  0.1603, -0.2870],\n",
       "                       [ 0.2667, -0.1390,  0.2081,  ...,  0.5195,  0.1911,  0.2057]],\n",
       "                      device='cuda:0')),\n",
       "              ('gat2.lin_l.bias',\n",
       "               tensor([ 5.5890e-02,  3.1473e-01, -8.7846e-02,  1.7730e-01,  6.8679e-02,\n",
       "                        7.5186e-02,  9.3879e-02, -6.9117e-02,  1.8811e-01,  2.2480e-01,\n",
       "                        4.6979e-02, -1.6144e-02, -5.9729e-02, -7.2298e-03,  1.6962e-01,\n",
       "                        1.4937e-02,  3.7616e-02,  4.5362e-02,  1.5856e-01,  9.9524e-02,\n",
       "                       -2.0748e-01,  9.0780e-02,  8.2105e-02,  7.8631e-02,  1.7499e-02,\n",
       "                        2.4903e-02, -1.5889e-02,  3.2448e-05,  1.2665e-01,  1.8134e-01,\n",
       "                       -6.6013e-02,  1.0512e-02], device='cuda:0')),\n",
       "              ('gat2.lin_r.weight',\n",
       "               tensor([[-0.1162,  0.1655,  0.0134,  ...,  0.0608,  0.0512,  0.0751],\n",
       "                       [-0.2040,  0.0104,  0.0719,  ..., -0.0861, -0.3432, -0.3097],\n",
       "                       [-0.1864, -0.0068,  0.0345,  ..., -0.0889,  0.2616,  0.0832],\n",
       "                       ...,\n",
       "                       [-0.0092, -0.1105, -0.1229,  ...,  0.2759,  0.1774, -0.1582],\n",
       "                       [-0.1427,  0.2206,  0.0221,  ..., -0.5290,  0.3511,  0.2624],\n",
       "                       [ 0.4967, -0.1332, -0.1635,  ..., -0.0384,  0.1631, -0.1022]],\n",
       "                      device='cuda:0')),\n",
       "              ('gat2.lin_r.bias',\n",
       "               tensor([ 0.0104,  0.0278, -0.1841, -0.0963,  0.2077, -0.0201,  0.0517, -0.0743,\n",
       "                        0.1207, -0.0206, -0.1118,  0.0892, -0.2336, -0.0674,  0.0759,  0.2000,\n",
       "                        0.0292,  0.0278, -0.1052, -0.0679, -0.1093, -0.1102,  0.0705, -0.0507,\n",
       "                       -0.0575, -0.2073, -0.0277,  0.0470, -0.1374,  0.0237,  0.0382, -0.0154],\n",
       "                      device='cuda:0')),\n",
       "              ('gat2.lin_edge.weight',\n",
       "               tensor([[-3.0916e-01, -1.7173e-01,  1.2954e-01, -1.8097e-01,  4.0504e-01,\n",
       "                        -2.6744e-01, -1.3695e-01,  2.6088e-01],\n",
       "                       [-4.5390e-02, -1.8706e-01, -1.1777e-01, -1.0639e-01,  9.2567e-02,\n",
       "                        -2.4080e-01, -2.9879e-01,  7.3203e-02],\n",
       "                       [-2.0565e-01,  1.6255e-01,  9.7779e-02,  3.2684e-01,  3.3853e-01,\n",
       "                         3.9221e-02,  6.2603e-03,  9.9178e-02],\n",
       "                       [-8.8860e-02, -6.0322e-02, -3.9967e-02, -1.1107e-01,  2.6072e-01,\n",
       "                         7.5345e-02,  1.1780e-01,  4.5195e-02],\n",
       "                       [-2.2023e-01,  1.1095e-01, -2.4090e-01,  2.4367e-01, -3.4308e-01,\n",
       "                         2.7938e-01,  3.3815e-01,  2.0088e-02],\n",
       "                       [-3.0994e-01,  3.1734e-01, -2.5225e-02, -2.5305e-02,  3.6853e-01,\n",
       "                        -2.4049e-01,  4.4347e-02, -4.1543e-01],\n",
       "                       [ 1.6426e-01, -3.5287e-01,  2.7857e-01,  4.4566e-02, -9.0519e-02,\n",
       "                         2.4354e-02, -3.1245e-01, -1.4662e-01],\n",
       "                       [-1.9215e-01, -8.7114e-02, -1.6591e-03,  9.6113e-02,  2.6083e-01,\n",
       "                         8.0400e-02,  1.1627e-01, -2.7523e-01],\n",
       "                       [-3.2194e-02, -3.7245e-01,  2.8178e-01,  1.5880e-01,  2.6032e-01,\n",
       "                         3.4110e-01, -3.3182e-01,  6.1995e-02],\n",
       "                       [-4.6341e-02, -3.5190e-01, -5.5202e-02,  3.7831e-01, -5.6658e-02,\n",
       "                         2.0713e-01, -3.3177e-01, -2.9618e-01],\n",
       "                       [-4.3776e-02,  3.3264e-01,  7.3703e-02,  3.2872e-02,  3.4127e-01,\n",
       "                        -1.4845e-01, -3.1660e-01, -6.6758e-02],\n",
       "                       [ 7.5372e-02,  2.8923e-01,  4.1635e-01,  1.9346e-01, -3.4100e-01,\n",
       "                         1.5747e-02, -1.2537e-01, -2.5745e-01],\n",
       "                       [-2.0061e-01, -2.3662e-02, -1.4641e-01,  1.8167e-02,  4.0722e-01,\n",
       "                        -2.7922e-01, -1.9747e-01,  3.2656e-01],\n",
       "                       [-8.8663e-02, -1.0927e-01,  3.4568e-01, -2.2054e-01, -2.4878e-01,\n",
       "                         3.9939e-01, -8.5691e-02, -6.7004e-02],\n",
       "                       [ 2.9131e-01, -1.0388e-02, -2.1698e-01, -8.6824e-02,  1.7886e-01,\n",
       "                        -3.6596e-01,  1.6447e-01,  1.5529e-01],\n",
       "                       [-1.2333e-01,  3.1602e-01,  1.3363e-01, -1.7283e-01,  2.9021e-01,\n",
       "                         8.3635e-02,  2.7841e-01, -1.0033e-01],\n",
       "                       [ 2.4079e-01, -3.0575e-02,  1.5254e-01,  3.0396e-01, -1.0306e-01,\n",
       "                         1.0752e-01,  2.5495e-01,  1.1667e-02],\n",
       "                       [-4.8882e-02, -6.3055e-02, -1.9466e-01, -3.7738e-01, -1.8689e-01,\n",
       "                         2.4804e-01,  2.1473e-01, -2.0106e-04],\n",
       "                       [-4.1950e-01, -6.4200e-02,  3.6432e-01, -3.3849e-01,  1.4104e-01,\n",
       "                         2.2675e-01,  3.4030e-01, -3.2965e-01],\n",
       "                       [-1.9100e-01,  2.0534e-01, -1.4351e-01, -2.3207e-01,  9.8154e-02,\n",
       "                         2.7143e-01,  1.1830e-01,  1.3064e-01],\n",
       "                       [-2.2142e-01, -1.7461e-01,  3.3197e-01, -1.2123e-01,  5.4264e-02,\n",
       "                        -1.8807e-02, -1.1279e-01, -2.2053e-01],\n",
       "                       [ 1.5486e-01, -1.6941e-01, -5.8132e-02,  3.0950e-01,  2.6342e-01,\n",
       "                         3.7619e-01,  3.9103e-02,  3.6678e-01],\n",
       "                       [-1.1223e-01, -1.3184e-01, -3.1018e-01, -1.1198e-01,  4.0607e-01,\n",
       "                        -3.5659e-01,  3.0120e-01, -1.9209e-01],\n",
       "                       [ 2.5193e-01,  1.8433e-01, -8.1682e-02, -3.0752e-01, -2.8477e-01,\n",
       "                         2.6999e-01, -2.2316e-01, -2.8044e-03],\n",
       "                       [ 1.9635e-01, -8.9664e-03,  1.0492e-01,  9.2982e-02,  6.0933e-02,\n",
       "                         3.7324e-01,  3.1484e-01,  3.0998e-01],\n",
       "                       [-2.5988e-01,  3.0042e-01, -8.6537e-02,  3.2499e-01,  2.6294e-01,\n",
       "                         1.2968e-01, -3.5889e-01,  1.8561e-01],\n",
       "                       [-2.7262e-01, -2.2588e-01, -2.3835e-02,  3.7072e-01, -3.3159e-01,\n",
       "                        -1.1817e-01,  2.5002e-01, -1.7871e-01],\n",
       "                       [-2.0520e-01,  2.0312e-02, -3.6280e-01,  3.6771e-01,  7.2458e-02,\n",
       "                        -7.2302e-02,  7.3668e-02, -1.5786e-01],\n",
       "                       [ 2.7165e-01, -4.4073e-01, -2.3555e-01,  8.6719e-02, -1.7865e-01,\n",
       "                        -3.1868e-01, -1.1949e-01,  3.1517e-01],\n",
       "                       [-2.7637e-01,  7.9689e-02, -1.5619e-01,  2.8717e-01,  2.8753e-01,\n",
       "                        -3.5844e-01, -3.0562e-01,  3.1647e-01],\n",
       "                       [ 4.2549e-01, -3.2452e-01, -1.1484e-01, -1.0360e-01, -2.1656e-01,\n",
       "                         3.1369e-01,  1.8028e-01, -2.2956e-01],\n",
       "                       [ 1.1051e-01, -1.3573e-01, -3.4576e-01, -3.7533e-01,  1.6226e-01,\n",
       "                        -1.2051e-01,  1.4865e-01,  6.9699e-04]], device='cuda:0')),\n",
       "              ('edge_mlp.0.weight',\n",
       "               tensor([[ 0.3149, -0.3800,  0.0293,  ..., -0.1429,  0.0339,  0.0628],\n",
       "                       [ 0.2461, -0.2266, -0.0362,  ..., -0.0919, -0.0852, -0.0279],\n",
       "                       [-0.0550,  0.3700, -0.0077,  ...,  0.1007, -0.1150,  0.0124],\n",
       "                       ...,\n",
       "                       [ 0.1261, -0.0731,  0.0890,  ..., -0.0123, -0.0657,  0.1606],\n",
       "                       [ 0.2823, -0.1910,  0.1131,  ..., -0.0206,  0.0494,  0.0349],\n",
       "                       [-0.1715,  0.3278, -0.1564,  ..., -0.0867, -0.0492,  0.1362]],\n",
       "                      device='cuda:0')),\n",
       "              ('edge_mlp.0.bias',\n",
       "               tensor([-0.0432, -0.0583, -0.0269,  0.0727, -0.0765, -0.0653,  0.0345,  0.1995,\n",
       "                        0.0259, -0.2295,  0.0441, -0.0814,  0.0378, -0.1414, -0.1289, -0.0769,\n",
       "                       -0.0603, -0.1087,  0.0173,  0.0129, -0.1786,  0.0087,  0.0352,  0.0736,\n",
       "                       -0.0647, -0.0959, -0.0289, -0.0939,  0.0465,  0.0920,  0.0427, -0.2335],\n",
       "                      device='cuda:0')),\n",
       "              ('edge_mlp.2.weight',\n",
       "               tensor([[ 0.2083,  0.0942,  0.2661,  0.1141, -0.0964, -0.1098,  0.1730, -0.2313,\n",
       "                         0.2151, -0.1572,  0.1852,  0.2976, -0.1144, -0.2030, -0.2163,  0.0991,\n",
       "                         0.0880,  0.1103,  0.1642, -0.2052, -0.1142,  0.1658,  0.0834,  0.1006,\n",
       "                        -0.1381, -0.1840,  0.2478,  0.1360, -0.2902,  0.1023,  0.2180, -0.2538]],\n",
       "                      device='cuda:0')),\n",
       "              ('edge_mlp.2.bias', tensor([-0.0579], device='cuda:0'))]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TarGraphDataset(datafile)\n",
    "split = int(len(dataset)*0.95)\n",
    "train_ds = Subset(dataset, range(split))\n",
    "val_ds   = Subset(dataset, range(split, len(dataset)))\n",
    "train_loader = make_loader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = make_loader(val_ds, batch_size=16, shuffle=True)\n",
    "\n",
    "model = GraphAttentionNetwork(in_dim = 96, edge_in_dim = 197, edge_emb_dim = 8, hidden1 = 64, hidden2 = 32, heads = 1)\n",
    "\n",
    "hist, _ = train_model(model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            num_epochs     = 10,\n",
    "            lr             = 1e-4,\n",
    "            validate_every = 1,\n",
    "            patience       = 10,\n",
    "            device         = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc1814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "torch.save(model.state_dict(), \"modelbatch10epoch.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
